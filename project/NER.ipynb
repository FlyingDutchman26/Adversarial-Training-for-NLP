{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRML Final PJ Part 2\n",
    "## Adversarial Training for Chinese NER(Name Entity Recognition)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型和基本代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/pjli/anaconda3/envs/nlptorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device= cuda:0\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "import random\n",
    "from transformers import BertTokenizer,AutoTokenizer\n",
    "from transformers import BertModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "#加载字典和分词工具\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese') # Why use BertTokenizer then: list out of range?\n",
    "# 调参\n",
    "args = {\n",
    "    'max_length':128,\n",
    "    'batch_size':32,\n",
    "    'epoch':3,\n",
    "    'init_lr':2e-5,\n",
    "    'seed':521,\n",
    "    'device':'cuda:0',\n",
    "}\n",
    "\n",
    "device =  args['device'] if torch.cuda.is_available() else 'cpu'\n",
    "print('device=', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,split = 'train'): \n",
    "        # 人民日报NER数据集\n",
    "        #names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "        #在线加载数据集\n",
    "        #dataset = load_dataset(path='peoples_daily_ner', split=split)\n",
    "        # 离线加载数据集\n",
    "        dataset = load_from_disk(dataset_path='./peoples_daily_ner')[split]\n",
    "        def f(data):\n",
    "            return len(data['tokens']) <= 48 - 2\n",
    "        dataset = dataset.filter(f)\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        tokens = self.dataset[i]['tokens']\n",
    "        labels = self.dataset[i]['ner_tags']\n",
    "\n",
    "        return tokens, labels\n",
    "    \n",
    "\n",
    "class NERModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained_bert = BertModel.from_pretrained('bert-base-chinese')\n",
    "        self.pretrained_bert.to(device)\n",
    "        self.classifier = torch.nn.Linear(768, 8)\n",
    "        self.crf = CRF(8, batch_first=True)\n",
    "        self.emissions = None\n",
    "    def loss(self,input_ids, attention_mask, token_type_ids, labels):\n",
    "        out = self.pretrained_bert(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids).last_hidden_state\n",
    "        self.emissions = self.classifier(out)\n",
    "        loss = self.crf(emissions=self.emissions, tags=labels, mask=attention_mask.byte())\n",
    "        return loss\n",
    "    \n",
    "    def forward(self,input_ids, attention_mask, token_type_ids):\n",
    "        out = self.pretrained_bert(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids).last_hidden_state\n",
    "        logits = self.classifier(out)\n",
    "        tags = self.crf.decode(emissions=logits,  mask=attention_mask.byte())\n",
    "        return tags\n",
    "    \n",
    "#数据整理函数\n",
    "def collate_fn(data):\n",
    "    tokens = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    data = tokenizer.batch_encode_plus(tokens,\n",
    "                                         truncation=True,\n",
    "                                         padding=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         is_split_into_words=True)\n",
    "\n",
    "    lens = data['input_ids'].shape[1]\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [7] + labels[i]\n",
    "        labels[i] += [7] * lens\n",
    "        labels[i] = labels[i][:lens]\n",
    "    \n",
    "    #input_ids 就是编码后的词\n",
    "    #token_type_ids 第一个句子和特殊符号的位置是0,第二个句子的位置是1\n",
    "    #attention_mask pad的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids'].to(device)\n",
    "    attention_mask = data['attention_mask'].to(device)\n",
    "    token_type_ids = data['token_type_ids'].to(device)\n",
    "    labels = torch.LongTensor(labels).to(device)\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "#对计算结果和label变形,并且移除pad\n",
    "def reshape_and_remove_pad(outs, labels, attention_mask):\n",
    "    #变形,便于计算loss\n",
    "    #[b, lens(经过CRF已经不一样长)] -> [b*lens] (本身CRF会只保留有效长度)\n",
    "    outs = torch.tensor(sum(outs,[]),device=device)\n",
    "    #[b, lens] -> [b*lens]\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    #忽略对pad的计算结果\n",
    "    #[b, lens] -> [b*lens - pad]\n",
    "    # attention_mask: pad位置是0，非pad为1\n",
    "    select = attention_mask.reshape(-1) == 1\n",
    "    labels = labels[select]\n",
    "\n",
    "    return outs, labels\n",
    "\n",
    "#获取正确数量和总数\n",
    "def get_correct_and_total_count(labels, outs):\n",
    "    assert(len(labels) == len(outs))\n",
    "    # print('debug')\n",
    "    # print(outs)\n",
    "    # print(labels)\n",
    "    correct = (outs == labels).sum().item()\n",
    "    total = len(labels)\n",
    "\n",
    "    #计算除了0以外元素的正确率,因为0太多了,包括的话,正确率很容易虚高\n",
    "    select = labels != 0\n",
    "    outs = outs[select]\n",
    "    labels = labels[select]\n",
    "    correct_content = (outs == labels).sum().item()\n",
    "    total_content = len(labels)\n",
    "\n",
    "    return correct, total, correct_content, total_content\n",
    "\n",
    "# 设置随机种子函数\n",
    "def setup_seed(seed=0):\n",
    "    torch.manual_seed(seed)  # 为CPU设置随机种子\n",
    "    random.seed(seed)  # Python random module.\n",
    "    if torch.cuda.is_available():\n",
    "        # torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.cuda.manual_seed(seed)  # 为当前GPU设置随机种子\n",
    "        torch.cuda.manual_seed_all(seed)  # 为所有GPU设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at peoples_daily_ner/train/cache-88d75c6faa3faef6.arrow\n",
      "Loading cached processed dataset at peoples_daily_ner/validation/cache-3a479537469f0585.arrow\n",
      "Loading cached processed dataset at peoples_daily_ner/test/cache-74615302e494a10a.arrow\n"
     ]
    }
   ],
   "source": [
    "# 初始化随机种子\n",
    "setup_seed(args['seed'])\n",
    "#数据加载器\n",
    "loader = torch.utils.data.DataLoader(dataset=Dataset('train'),\n",
    "                                     batch_size=args['batch_size'],\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "loader_valid = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                              batch_size=400,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=False)\n",
    "loader_test = torch.utils.data.DataLoader(dataset=Dataset('test'),\n",
    "                                              batch_size=400,\n",
    "                                              collate_fn=collate_fn,\n",
    "                                              shuffle=True,\n",
    "                                            drop_last=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner 类\n",
    "不使用对抗训练与使用几种对抗训练方法的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER_Runner():\n",
    "    def __init__(self,model,optimizer) -> None:\n",
    "        self.model =model\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def train(self,train_loader,valid_loader,num_epoch=1):\n",
    "        self.model.train()\n",
    "        step = 0\n",
    "        best_accuracy = 0\n",
    "        for epoch in range(1,num_epoch+1):\n",
    "            for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(train_loader):\n",
    "                self.model.train()\n",
    "                loss = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outs = self.model.crf.decode(emissions=self.model.emissions, mask=attention_mask.byte())\n",
    "                    outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "                    correct, total, correct_content, total_content = get_correct_and_total_count(labels,outs)\n",
    "                    score1 = float(correct/total)\n",
    "                    score2 = float(correct_content/total_content)\n",
    "                    \n",
    "                valid_accuracy_all,valid_accuracy = self.evaluate(valid_loader)\n",
    "                if valid_accuracy >= best_accuracy:\n",
    "                    best_accuracy = valid_accuracy\n",
    "                    self.save_model()\n",
    "                    print(f'Best performance on valid set upgraded: accuracy: {best_accuracy}')\n",
    "                step += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                if step%10 == 0:\n",
    "                    print(f'[epoch]:{epoch},[step]:{step},[loss]:{loss},[score1]:{score1},[score2]:{score2}')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self,valid_loader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        correct_content = 0\n",
    "        total_content = 0\n",
    "        for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(valid_loader):\n",
    "            outs = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "            correct_t, total_t, correct_content_t, total_content_t = get_correct_and_total_count(labels,outs)\n",
    "            correct += correct_t\n",
    "            total += total_t\n",
    "            correct_content += correct_content_t\n",
    "            total_content += total_content_t\n",
    "            #print('debug: finish batch_id = ',batch_id)\n",
    "        score1 = float(correct/total)\n",
    "        score2 = float(correct_content/total_content)\n",
    "        return score1,score2\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def predict(self,test_loader):\n",
    "        self.load_model()\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        correct_content = 0\n",
    "        total_content = 0\n",
    "        for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(test_loader):\n",
    "            outs = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "            correct_t, total_t, correct_content_t, total_content_t = get_correct_and_total_count(labels,outs)\n",
    "            correct += correct_t\n",
    "            total += total_t\n",
    "            correct_content += correct_content_t\n",
    "            total_content += total_content_t\n",
    "        score1 = float(correct/total)\n",
    "        score2 = float(correct_content/total_content)\n",
    "        # print(total)\n",
    "        print(f'score1/score2 on test set:{score1},{score2}')\n",
    "        return score1,score2\n",
    "    \n",
    "    def save_model(self, save_path = './modelparams/ner_bestmodel_parms.pth'):\n",
    "        torch.save(self.model.state_dict(), save_path)\n",
    "\n",
    "    def load_model(self, model_path='./modelparams/ner_bestmodel_parms.pth'):\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "class NER_Runner_FGM(NER_Runner):\n",
    "    def __init__(self,model,optimizer,fgm = None) -> None:\n",
    "        super(NER_Runner_FGM,self).__init__(model,optimizer)\n",
    "        self.fgm = fgm\n",
    "        \n",
    "    def train(self,train_loader,valid_loader,num_epoch=1):\n",
    "        self.model.train()\n",
    "        step = 0\n",
    "        best_accuracy = 0\n",
    "        for epoch in range(1,num_epoch+1):\n",
    "            for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(train_loader):\n",
    "                self.model.train()\n",
    "                \n",
    "                loss = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                loss.backward()\n",
    "                self.fgm.attack()\n",
    "                loss_adv = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                loss_adv.backward()\n",
    "                self.fgm.restore()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outs = self.model.crf.decode(emissions=self.model.emissions, mask=attention_mask.byte())\n",
    "                    outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "                    correct, total, correct_content, total_content = get_correct_and_total_count(labels,outs)\n",
    "                    score1 = float(correct/total)\n",
    "                    score2 = float(correct_content/total_content)\n",
    "                    \n",
    "                valid_accuracy_all,valid_accuracy = self.evaluate(valid_loader)\n",
    "                if valid_accuracy >= best_accuracy:\n",
    "                    best_accuracy = valid_accuracy\n",
    "                    self.save_model()\n",
    "                    print(f'Best performance on valid set upgraded: accuracy: {best_accuracy}')\n",
    "                step += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                if step%10 == 0:\n",
    "                    print(f'[epoch]:{epoch},[step]:{step},[loss]:{loss},[score1]:{score1},[score2]:{score2}')\n",
    "\n",
    "class NER_Runner_PGD(NER_Runner):\n",
    "    def __init__(self,model,optimizer,pgd = None) -> None:\n",
    "        super(NER_Runner_PGD,self).__init__(model,optimizer)\n",
    "        self.pgd = pgd\n",
    "        \n",
    "    def train(self,train_loader,valid_loader,num_epoch=1):\n",
    "        self.model.train()\n",
    "        step = 0\n",
    "        best_accuracy = 0\n",
    "        K = self.pgd.k\n",
    "        for epoch in range(1,num_epoch+1):\n",
    "            for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(train_loader):\n",
    "                self.model.train()\n",
    "                loss = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                loss.backward()\n",
    "                self.pgd.backup_grad()\n",
    "                for t in range(K):\n",
    "                    self.pgd.attack(is_first_attack=(t==0))\n",
    "                    if t == K-1:\n",
    "                        self.pgd.restore_grad()\n",
    "                    else:\n",
    "                        self.optimizer.zero_grad()\n",
    "                        \n",
    "                    loss_adv = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                    loss_adv.backward() # 前面就按公式正常迭代梯度，最后一次在最初梯度上累计一次\n",
    "                    \n",
    "                self.pgd.restore()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    outs = self.model.crf.decode(emissions=self.model.emissions, mask=attention_mask.byte())\n",
    "                    outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "                    correct, total, correct_content, total_content = get_correct_and_total_count(labels,outs)\n",
    "                    score1 = float(correct/total)\n",
    "                    score2 = float(correct_content/total_content)\n",
    "                    \n",
    "                valid_accuracy_all,valid_accuracy = self.evaluate(valid_loader)\n",
    "                if valid_accuracy >= best_accuracy:\n",
    "                    best_accuracy = valid_accuracy\n",
    "                    self.save_model()\n",
    "                    print(f'Best performance on valid set upgraded: accuracy: {best_accuracy}')\n",
    "                step += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                if step%10 == 0:\n",
    "                    print(f'[epoch]:{epoch},[step]:{step},[loss]:{loss},[score1]:{score1},[score2]:{score2}')\n",
    "\n",
    "class NER_Runner_FreeLB(NER_Runner):\n",
    "    def __init__(self,model,optimizer,freelb = None):\n",
    "        super(NER_Runner_FreeLB,self).__init__(model,optimizer)\n",
    "        self.freelb = freelb\n",
    "    \n",
    "    def train(self,train_loader,valid_loader,num_epoch=1):\n",
    "        self.model.train()\n",
    "        step = 0\n",
    "        best_accuracy = 0\n",
    "        K = self.freelb.k\n",
    "        for epoch in range(1,num_epoch+1):\n",
    "            for batch_id, (input_ids, attention_mask, token_type_ids,labels) in enumerate(train_loader):\n",
    "                self.model.train()\n",
    "                loss = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                for t in range(K):\n",
    "                    self.freelb.backup_grad()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.freelb.attack(is_first_attack=(t==0))\n",
    "                    loss_adv = -self.model.loss(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids,labels=labels)        \n",
    "                    loss_adv.backward()\n",
    "                    self.freelb.backup_r_grad()\n",
    "                    self.freelb.upgrade_grad()\n",
    "                    self.freelb.upgrade_r_at()\n",
    "                    \n",
    "                self.freelb.restore()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                with torch.no_grad():\n",
    "                    outs = self.model.crf.decode(emissions=self.model.emissions, mask=attention_mask.byte())\n",
    "                    outs,labels = reshape_and_remove_pad(outs,labels,attention_mask)\n",
    "                    correct, total, correct_content, total_content = get_correct_and_total_count(labels,outs)\n",
    "                    score1 = float(correct/total)\n",
    "                    score2 = float(correct_content/total_content)\n",
    "                    \n",
    "                valid_accuracy_all,valid_accuracy = self.evaluate(valid_loader)\n",
    "                if valid_accuracy >= best_accuracy:\n",
    "                    best_accuracy = valid_accuracy\n",
    "                    self.save_model()\n",
    "                    print(f'Best performance on valid set upgraded: accuracy: {best_accuracy}')\n",
    "                step += 1\n",
    "                torch.cuda.empty_cache()\n",
    "                if step%10 == 0:\n",
    "                    print(f'[epoch]:{epoch},[step]:{step},[loss]:{loss},[score1]:{score1},[score2]:{score2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与测试"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 不使用对抗训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/remote-home/pjli/anaconda3/envs/nlptorch/lib/python3.7/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1666643004612/work/aten/src/ATen/native/TensorCompare.cpp:413.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on valid set upgraded: accuracy: 0.05914054744007942\n",
      "[epoch]:1,[step]:10,[loss]:849.5384521484375,[score1]:0.8070342205323194,[score2]:0.0\n",
      "Best performance on valid set upgraded: accuracy: 0.20252446461494825\n",
      "Best performance on valid set upgraded: accuracy: 0.37980428308041414\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.3901574244787973\n",
      "Best performance on valid set upgraded: accuracy: 0.3902992483335697\n",
      "Best performance on valid set upgraded: accuracy: 0.3902992483335697\n",
      "Best performance on valid set upgraded: accuracy: 0.39044107218834206\n",
      "Best performance on valid set upgraded: accuracy: 0.39044107218834206\n",
      "Best performance on valid set upgraded: accuracy: 0.39044107218834206\n",
      "[epoch]:1,[step]:20,[loss]:382.1465148925781,[score1]:0.9182915506035283,[score2]:0.42105263157894735\n",
      "Best performance on valid set upgraded: accuracy: 0.39058289604311447\n",
      "Best performance on valid set upgraded: accuracy: 0.3910083676074316\n",
      "Best performance on valid set upgraded: accuracy: 0.39171748688129343\n",
      "Best performance on valid set upgraded: accuracy: 0.3929939015742448\n",
      "Best performance on valid set upgraded: accuracy: 0.394979435541058\n",
      "Best performance on valid set upgraded: accuracy: 0.3976740887817331\n",
      "Best performance on valid set upgraded: accuracy: 0.40292157140831086\n",
      "Best performance on valid set upgraded: accuracy: 0.4115728265494256\n",
      "Best performance on valid set upgraded: accuracy: 0.4234860303503049\n",
      "Best performance on valid set upgraded: accuracy: 0.44093036448730677\n",
      "[epoch]:1,[step]:30,[loss]:313.30047607421875,[score1]:0.9011090573012939,[score2]:0.37790697674418605\n",
      "Best performance on valid set upgraded: accuracy: 0.466884129910651\n",
      "Best performance on valid set upgraded: accuracy: 0.49723443483193874\n",
      "Best performance on valid set upgraded: accuracy: 0.5287193305914055\n",
      "Best performance on valid set upgraded: accuracy: 0.559353283222238\n",
      "Best performance on valid set upgraded: accuracy: 0.587150758757623\n",
      "Best performance on valid set upgraded: accuracy: 0.6108353425046092\n",
      "Best performance on valid set upgraded: accuracy: 0.6291306197702453\n",
      "Best performance on valid set upgraded: accuracy: 0.6447312437952063\n",
      "Best performance on valid set upgraded: accuracy: 0.665153878882428\n",
      "Best performance on valid set upgraded: accuracy: 0.6858601616791944\n",
      "[epoch]:1,[step]:40,[loss]:145.642578125,[score1]:0.9554896142433235,[score2]:0.704225352112676\n",
      "Best performance on valid set upgraded: accuracy: 0.7057155013473266\n",
      "Best performance on valid set upgraded: accuracy: 0.7264217841440931\n",
      "Best performance on valid set upgraded: accuracy: 0.749255424762445\n",
      "Best performance on valid set upgraded: accuracy: 0.7723727130903418\n",
      "Best performance on valid set upgraded: accuracy: 0.7977591830945965\n",
      "Best performance on valid set upgraded: accuracy: 0.8120833924266062\n",
      "Best performance on valid set upgraded: accuracy: 0.8232874769536236\n",
      "Best performance on valid set upgraded: accuracy: 0.8288186072897461\n",
      "[epoch]:1,[step]:50,[loss]:137.96514892578125,[score1]:0.9626436781609196,[score2]:0.8040540540540541\n",
      "Best performance on valid set upgraded: accuracy: 0.8343497376258687\n",
      "Best performance on valid set upgraded: accuracy: 0.8427173450574387\n",
      "Best performance on valid set upgraded: accuracy: 0.8490994185221954\n",
      "Best performance on valid set upgraded: accuracy: 0.8513686001985534\n",
      "[epoch]:1,[step]:60,[loss]:101.96833801269531,[score1]:0.967479674796748,[score2]:0.8873239436619719\n",
      "Best performance on valid set upgraded: accuracy: 0.8529286626010495\n",
      "Best performance on valid set upgraded: accuracy: 0.8543469011487732\n",
      "Best performance on valid set upgraded: accuracy: 0.8556233158417246\n",
      "Best performance on valid set upgraded: accuracy: 0.8568997305346759\n",
      "Best performance on valid set upgraded: accuracy: 0.8573252020989931\n",
      "Best performance on valid set upgraded: accuracy: 0.858459792937172\n",
      "Best performance on valid set upgraded: accuracy: 0.8608707984683024\n",
      "[epoch]:1,[step]:70,[loss]:91.57501983642578,[score1]:0.9780018331805683,[score2]:0.8740740740740741\n",
      "Best performance on valid set upgraded: accuracy: 0.8644163948376117\n",
      "Best performance on valid set upgraded: accuracy: 0.8673946957878315\n",
      "Best performance on valid set upgraded: accuracy: 0.8733512976882711\n",
      "Best performance on valid set upgraded: accuracy: 0.8774641894766699\n",
      "Best performance on valid set upgraded: accuracy: 0.881293433555524\n",
      "Best performance on valid set upgraded: accuracy: 0.8871082116011914\n",
      "Best performance on valid set upgraded: accuracy: 0.8905119841157283\n",
      "Best performance on valid set upgraded: accuracy: 0.8944830520493547\n",
      "Best performance on valid set upgraded: accuracy: 0.8957594667423061\n",
      "[epoch]:1,[step]:80,[loss]:90.46900939941406,[score1]:0.9683168316831683,[score2]:0.8777777777777778\n",
      "Best performance on valid set upgraded: accuracy: 0.8977450007091192\n",
      "Best performance on valid set upgraded: accuracy: 0.8985959438377535\n",
      "Best performance on valid set upgraded: accuracy: 0.8990214154020706\n",
      "Best performance on valid set upgraded: accuracy: 0.8994468869663877\n",
      "Best performance on valid set upgraded: accuracy: 0.9021415402070628\n",
      "Best performance on valid set upgraded: accuracy: 0.902992483335697\n",
      "Best performance on valid set upgraded: accuracy: 0.9034179549000142\n",
      "Best performance on valid set upgraded: accuracy: 0.9062544319954616\n",
      "[epoch]:1,[step]:90,[loss]:56.62165069580078,[score1]:0.9810606060606061,[score2]:0.87248322147651\n",
      "Best performance on valid set upgraded: accuracy: 0.9122110338959013\n",
      "Best performance on valid set upgraded: accuracy: 0.9205786413274712\n",
      "Best performance on valid set upgraded: accuracy: 0.9236987661324635\n",
      "Best performance on valid set upgraded: accuracy: 0.9241242376967806\n",
      "[epoch]:1,[step]:100,[loss]:56.473121643066406,[score1]:0.981094527363184,[score2]:0.8888888888888888\n",
      "Best performance on valid set upgraded: accuracy: 0.92469153311587\n",
      "Best performance on valid set upgraded: accuracy: 0.9269607147922281\n",
      "Best performance on valid set upgraded: accuracy: 0.9314990781449439\n",
      "Best performance on valid set upgraded: accuracy: 0.934193731385619\n",
      "Best performance on valid set upgraded: accuracy: 0.9368883846262941\n",
      "Best performance on valid set upgraded: accuracy: 0.938732094738335\n",
      "[epoch]:1,[step]:110,[loss]:49.87147521972656,[score1]:0.9855630413859481,[score2]:0.9705882352941176\n",
      "Best performance on valid set upgraded: accuracy: 0.9390157424478798\n",
      "[epoch]:1,[step]:120,[loss]:30.348434448242188,[score1]:0.9938434476693052,[score2]:0.971830985915493\n",
      "Best performance on valid set upgraded: accuracy: 0.9400085094312863\n",
      "Best performance on valid set upgraded: accuracy: 0.9417103956885549\n",
      "Best performance on valid set upgraded: accuracy: 0.9425613388171891\n",
      "Best performance on valid set upgraded: accuracy: 0.9436959296553681\n",
      "[epoch]:1,[step]:130,[loss]:72.2087173461914,[score1]:0.9809705042816366,[score2]:0.8766233766233766\n",
      "[epoch]:1,[step]:140,[loss]:72.41178894042969,[score1]:0.9794826048171276,[score2]:0.9234449760765551\n",
      "[epoch]:1,[step]:150,[loss]:40.07273864746094,[score1]:0.991635687732342,[score2]:0.9753086419753086\n",
      "[epoch]:1,[step]:160,[loss]:42.16105651855469,[score1]:0.9901864573110893,[score2]:0.9358974358974359\n",
      "Best performance on valid set upgraded: accuracy: 0.9461069351864984\n",
      "Best performance on valid set upgraded: accuracy: 0.9497943554105801\n",
      "Best performance on valid set upgraded: accuracy: 0.9507871223939867\n",
      "[epoch]:1,[step]:170,[loss]:21.170501708984375,[score1]:0.9965065502183406,[score2]:0.9901477832512315\n",
      "Best performance on valid set upgraded: accuracy: 0.9522053609417104\n",
      "Best performance on valid set upgraded: accuracy: 0.9540490710537513\n",
      "Best performance on valid set upgraded: accuracy: 0.954332718763296\n",
      "[epoch]:1,[step]:180,[loss]:80.75402069091797,[score1]:0.9719887955182073,[score2]:0.8947368421052632\n",
      "[epoch]:1,[step]:190,[loss]:37.49913024902344,[score1]:0.9908508691674291,[score2]:0.9627329192546584\n",
      "[epoch]:1,[step]:200,[loss]:29.82440185546875,[score1]:0.9924242424242424,[score2]:0.975609756097561\n",
      "[epoch]:1,[step]:210,[loss]:45.29322052001953,[score1]:0.9901697944593387,[score2]:0.9494949494949495\n",
      "Best performance on valid set upgraded: accuracy: 0.955467309601475\n",
      "Best performance on valid set upgraded: accuracy: 0.9558927811657921\n",
      "Best performance on valid set upgraded: accuracy: 0.9573110197135158\n",
      "Best performance on valid set upgraded: accuracy: 0.9578783151326054\n",
      "[epoch]:1,[step]:220,[loss]:6.583000183105469,[score1]:1.0,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.960431144518508\n",
      "[epoch]:1,[step]:230,[loss]:54.89573669433594,[score1]:0.9824561403508771,[score2]:0.9069767441860465\n",
      "Best performance on valid set upgraded: accuracy: 0.9621330307757765\n",
      "Best performance on valid set upgraded: accuracy: 0.9636930931782726\n",
      "Best performance on valid set upgraded: accuracy: 0.9646858601616792\n",
      "[epoch]:1,[step]:240,[loss]:106.51324462890625,[score1]:0.9701357466063348,[score2]:0.8711340206185567\n",
      "[epoch]:1,[step]:250,[loss]:43.40260314941406,[score1]:0.9861495844875346,[score2]:0.9470198675496688\n",
      "[epoch]:1,[step]:260,[loss]:52.41504669189453,[score1]:0.9860594795539034,[score2]:0.9102564102564102\n",
      "[epoch]:1,[step]:270,[loss]:67.93438720703125,[score1]:0.9830810329474622,[score2]:0.9271844660194175\n",
      "[epoch]:1,[step]:280,[loss]:25.88104248046875,[score1]:0.9954044117647058,[score2]:0.9705882352941176\n",
      "[epoch]:1,[step]:290,[loss]:40.597686767578125,[score1]:0.9855072463768116,[score2]:0.9344262295081968\n",
      "Best performance on valid set upgraded: accuracy: 0.9648276840164516\n",
      "Best performance on valid set upgraded: accuracy: 0.9653949794355411\n",
      "[epoch]:1,[step]:300,[loss]:44.48240661621094,[score1]:0.982824427480916,[score2]:0.9666666666666667\n",
      "[epoch]:1,[step]:310,[loss]:34.752655029296875,[score1]:0.9894837476099426,[score2]:0.9295774647887324\n",
      "Best performance on valid set upgraded: accuracy: 0.9675223372571267\n",
      "Best performance on valid set upgraded: accuracy: 0.967664161111899\n",
      "Best performance on valid set upgraded: accuracy: 0.9680896326762162\n",
      "[epoch]:1,[step]:320,[loss]:51.619056701660156,[score1]:0.9849094567404426,[score2]:0.9337349397590361\n",
      "Best performance on valid set upgraded: accuracy: 0.9686569280953057\n",
      "[epoch]:1,[step]:330,[loss]:44.14457702636719,[score1]:0.9891304347826086,[score2]:0.9375\n",
      "[epoch]:1,[step]:340,[loss]:43.79247283935547,[score1]:0.9894736842105263,[score2]:0.9719101123595506\n",
      "[epoch]:1,[step]:350,[loss]:34.23072052001953,[score1]:0.9876308277830638,[score2]:0.9352941176470588\n",
      "[epoch]:1,[step]:360,[loss]:10.575485229492188,[score1]:0.9990958408679927,[score2]:0.9932432432432432\n",
      "[epoch]:1,[step]:370,[loss]:70.21552276611328,[score1]:0.9855769230769231,[score2]:0.9441624365482234\n",
      "[epoch]:1,[step]:380,[loss]:23.359756469726562,[score1]:0.9929718875502008,[score2]:0.9647058823529412\n",
      "[epoch]:1,[step]:390,[loss]:152.11941528320312,[score1]:0.9680232558139535,[score2]:0.8388888888888889\n",
      "[epoch]:2,[step]:400,[loss]:22.558013916015625,[score1]:0.9961612284069098,[score2]:0.9932432432432432\n",
      "[epoch]:2,[step]:410,[loss]:14.301620483398438,[score1]:0.9980676328502416,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9690823996596227\n",
      "[epoch]:2,[step]:420,[loss]:20.274124145507812,[score1]:0.9953051643192489,[score2]:0.9784172661870504\n",
      "[epoch]:2,[step]:430,[loss]:21.040451049804688,[score1]:0.9962370649106302,[score2]:0.9856115107913669\n",
      "[epoch]:2,[step]:440,[loss]:18.576377868652344,[score1]:0.9969262295081968,[score2]:0.9842931937172775\n",
      "[epoch]:2,[step]:450,[loss]:37.78851318359375,[score1]:0.9885714285714285,[score2]:0.9939393939393939\n",
      "[epoch]:2,[step]:460,[loss]:10.613883972167969,[score1]:0.9959555106167847,[score2]:0.9764705882352941\n",
      "[epoch]:2,[step]:470,[loss]:9.41229248046875,[score1]:0.9980582524271845,[score2]:0.9887005649717514\n",
      "[epoch]:2,[step]:480,[loss]:47.27471923828125,[score1]:0.9856184084372004,[score2]:0.9252873563218391\n",
      "Best performance on valid set upgraded: accuracy: 0.9690823996596227\n",
      "Best performance on valid set upgraded: accuracy: 0.9695078712239399\n",
      "Best performance on valid set upgraded: accuracy: 0.9697915189334846\n",
      "Best performance on valid set upgraded: accuracy: 0.9699333427882569\n",
      "[epoch]:2,[step]:490,[loss]:12.197311401367188,[score1]:0.9973214285714286,[score2]:1.0\n",
      "[epoch]:2,[step]:500,[loss]:4.9584503173828125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:510,[loss]:11.310356140136719,[score1]:0.9990281827016521,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9699333427882569\n",
      "[epoch]:2,[step]:520,[loss]:16.188385009765625,[score1]:0.9981751824817519,[score2]:0.9895287958115183\n",
      "[epoch]:2,[step]:530,[loss]:22.982696533203125,[score1]:0.9931170108161259,[score2]:0.9567901234567902\n",
      "[epoch]:2,[step]:540,[loss]:14.777793884277344,[score1]:0.9940417080436942,[score2]:0.974025974025974\n",
      "[epoch]:2,[step]:550,[loss]:53.54472351074219,[score1]:0.9775700934579439,[score2]:0.9090909090909091\n",
      "[epoch]:2,[step]:560,[loss]:23.668724060058594,[score1]:0.9935543278084714,[score2]:0.9775280898876404\n",
      "[epoch]:2,[step]:570,[loss]:9.52044677734375,[score1]:0.9980787704130644,[score2]:1.0\n",
      "[epoch]:2,[step]:580,[loss]:10.505706787109375,[score1]:0.9979899497487437,[score2]:0.9938271604938271\n",
      "[epoch]:2,[step]:590,[loss]:7.71002197265625,[score1]:0.9991031390134529,[score2]:1.0\n",
      "[epoch]:2,[step]:600,[loss]:15.370391845703125,[score1]:0.996003996003996,[score2]:0.9774436090225563\n",
      "[epoch]:2,[step]:610,[loss]:17.6240234375,[score1]:0.994759825327511,[score2]:0.9548872180451128\n",
      "[epoch]:2,[step]:620,[loss]:5.82806396484375,[score1]:0.9990774907749077,[score2]:0.9947643979057592\n",
      "Best performance on valid set upgraded: accuracy: 0.9706424620621188\n",
      "Best performance on valid set upgraded: accuracy: 0.9707842859168913\n",
      "Best performance on valid set upgraded: accuracy: 0.9714934051907531\n",
      "Best performance on valid set upgraded: accuracy: 0.9724861721741597\n",
      "Best performance on valid set upgraded: accuracy: 0.9729116437384768\n",
      "Best performance on valid set upgraded: accuracy: 0.9734789391575663\n",
      "Best performance on valid set upgraded: accuracy: 0.9744717061409729\n",
      "[epoch]:2,[step]:630,[loss]:33.768280029296875,[score1]:0.9868544600938968,[score2]:0.9401197604790419\n",
      "[epoch]:2,[step]:640,[loss]:15.095535278320312,[score1]:0.9961240310077519,[score2]:0.9726027397260274\n",
      "[epoch]:2,[step]:650,[loss]:21.274520874023438,[score1]:0.9915572232645403,[score2]:0.9890710382513661\n",
      "[epoch]:2,[step]:660,[loss]:39.89973449707031,[score1]:0.9913294797687862,[score2]:0.9760765550239234\n",
      "[epoch]:2,[step]:670,[loss]:17.146629333496094,[score1]:0.9971883786316776,[score2]:0.98125\n",
      "[epoch]:2,[step]:680,[loss]:38.98225402832031,[score1]:0.9929859719438878,[score2]:0.9669811320754716\n",
      "[epoch]:2,[step]:690,[loss]:9.290565490722656,[score1]:0.9971936389148737,[score2]:1.0\n",
      "[epoch]:2,[step]:700,[loss]:24.252548217773438,[score1]:0.995846313603323,[score2]:0.9887640449438202\n",
      "[epoch]:2,[step]:710,[loss]:29.43505859375,[score1]:0.9949341438703141,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "[epoch]:2,[step]:720,[loss]:32.82434844970703,[score1]:0.9886714727085479,[score2]:0.979381443298969\n",
      "[epoch]:2,[step]:730,[loss]:7.250907897949219,[score1]:0.9959016393442623,[score2]:0.9818181818181818\n",
      "[epoch]:2,[step]:740,[loss]:10.818283081054688,[score1]:0.997104247104247,[score2]:0.9838709677419355\n",
      "Best performance on valid set upgraded: accuracy: 0.9754644731243796\n",
      "Best performance on valid set upgraded: accuracy: 0.9767408878173309\n",
      "Best performance on valid set upgraded: accuracy: 0.9767408878173309\n",
      "[epoch]:2,[step]:750,[loss]:17.737808227539062,[score1]:0.9958549222797928,[score2]:1.0\n",
      "[epoch]:2,[step]:760,[loss]:27.965179443359375,[score1]:0.9893711248892826,[score2]:0.9194630872483222\n",
      "[epoch]:2,[step]:770,[loss]:14.769073486328125,[score1]:0.9954627949183303,[score2]:0.9880239520958084\n",
      "[epoch]:2,[step]:780,[loss]:2.5979156494140625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:790,[loss]:7.932281494140625,[score1]:0.9989785495403473,[score2]:0.9948186528497409\n",
      "[epoch]:3,[step]:800,[loss]:11.246170043945312,[score1]:0.9963133640552996,[score2]:1.0\n",
      "[epoch]:3,[step]:810,[loss]:13.861526489257812,[score1]:0.9990138067061144,[score2]:1.0\n",
      "[epoch]:3,[step]:820,[loss]:23.3798828125,[score1]:0.989065606361829,[score2]:0.971830985915493\n",
      "[epoch]:3,[step]:830,[loss]:20.72576904296875,[score1]:0.9935897435897436,[score2]:0.9595375722543352\n",
      "[epoch]:3,[step]:840,[loss]:28.259292602539062,[score1]:0.9919137466307277,[score2]:0.9731543624161074\n",
      "[epoch]:3,[step]:850,[loss]:8.631576538085938,[score1]:0.997002997002997,[score2]:0.9824561403508771\n",
      "[epoch]:3,[step]:860,[loss]:9.498245239257812,[score1]:0.997078870496592,[score2]:0.9897959183673469\n",
      "[epoch]:3,[step]:870,[loss]:5.5955352783203125,[score1]:0.998019801980198,[score2]:1.0\n",
      "[epoch]:3,[step]:880,[loss]:9.864456176757812,[score1]:0.9955673758865248,[score2]:1.0\n",
      "[epoch]:3,[step]:890,[loss]:24.506362915039062,[score1]:0.9949290060851927,[score2]:0.9728260869565217\n",
      "[epoch]:3,[step]:900,[loss]:20.791244506835938,[score1]:0.9914448669201521,[score2]:0.9666666666666667\n",
      "[epoch]:3,[step]:910,[loss]:33.48890686035156,[score1]:0.9915094339622641,[score2]:0.9502762430939227\n",
      "[epoch]:3,[step]:920,[loss]:7.151580810546875,[score1]:0.9961759082217974,[score2]:1.0\n",
      "[epoch]:3,[step]:930,[loss]:2.2805328369140625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:940,[loss]:8.75860595703125,[score1]:0.9973070017953322,[score2]:0.9829545454545454\n",
      "[epoch]:3,[step]:950,[loss]:8.773025512695312,[score1]:0.9980392156862745,[score2]:1.0\n",
      "[epoch]:3,[step]:960,[loss]:20.734375,[score1]:0.9936247723132969,[score2]:0.9660194174757282\n",
      "[epoch]:3,[step]:970,[loss]:4.9244384765625,[score1]:0.9980879541108987,[score2]:0.9899497487437185\n",
      "[epoch]:3,[step]:980,[loss]:3.50201416015625,[score1]:0.998989898989899,[score2]:0.9946236559139785\n",
      "[epoch]:3,[step]:990,[loss]:12.48876953125,[score1]:0.9981735159817352,[score2]:0.9922480620155039\n",
      "[epoch]:3,[step]:1000,[loss]:7.882415771484375,[score1]:0.9981132075471698,[score2]:1.0\n",
      "[epoch]:3,[step]:1010,[loss]:12.792129516601562,[score1]:0.9971804511278195,[score2]:0.985781990521327\n",
      "[epoch]:3,[step]:1020,[loss]:5.728118896484375,[score1]:0.9990439770554493,[score2]:0.9940828402366864\n",
      "[epoch]:3,[step]:1030,[loss]:16.893386840820312,[score1]:0.9890219560878244,[score2]:0.9295774647887324\n",
      "[epoch]:3,[step]:1040,[loss]:9.354248046875,[score1]:0.996011964107677,[score2]:1.0\n",
      "[epoch]:3,[step]:1050,[loss]:6.8973388671875,[score1]:0.9991445680068435,[score2]:0.9956140350877193\n",
      "[epoch]:3,[step]:1060,[loss]:3.39520263671875,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1070,[loss]:21.95758056640625,[score1]:0.9916974169741697,[score2]:0.9635416666666666\n",
      "[epoch]:3,[step]:1080,[loss]:10.32562255859375,[score1]:0.9970559371933267,[score2]:0.98\n",
      "[epoch]:3,[step]:1090,[loss]:8.321731567382812,[score1]:0.9973935708079931,[score2]:0.9803921568627451\n",
      "[epoch]:3,[step]:1100,[loss]:14.7645263671875,[score1]:0.9962264150943396,[score2]:0.978494623655914\n",
      "[epoch]:3,[step]:1110,[loss]:14.7969970703125,[score1]:0.9958762886597938,[score2]:0.9748427672955975\n",
      "[epoch]:3,[step]:1120,[loss]:4.2676544189453125,[score1]:0.9990909090909091,[score2]:0.993103448275862\n",
      "[epoch]:3,[step]:1130,[loss]:20.677047729492188,[score1]:0.9909365558912386,[score2]:0.972972972972973\n",
      "[epoch]:3,[step]:1140,[loss]:2.090179443359375,[score1]:1.0,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9770245355268756\n",
      "Best performance on valid set upgraded: accuracy: 0.9780173025102822\n",
      "Best performance on valid set upgraded: accuracy: 0.9784427740745993\n",
      "Best performance on valid set upgraded: accuracy: 0.9791518933484612\n",
      "Best performance on valid set upgraded: accuracy: 0.979435541058006\n",
      "[epoch]:3,[step]:1150,[loss]:7.68310546875,[score1]:0.9982347749338041,[score2]:0.9910714285714286\n",
      "[epoch]:3,[step]:1160,[loss]:37.803863525390625,[score1]:0.9896421845574388,[score2]:0.9949238578680203\n",
      "[epoch]:3,[step]:1170,[loss]:24.4246826171875,[score1]:0.9953789279112755,[score2]:0.9846153846153847\n",
      "[epoch]:3,[step]:1180,[loss]:5.8406982421875,[score1]:0.9973021582733813,[score2]:0.9813664596273292\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW,Adam\n",
    "\n",
    "model = NERModel()\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=args['init_lr']) # 这个真的是应该小啊！2e-5 1e-5这种才可以，5e-4直接崩盘！50%都不到\n",
    "runner = NER_Runner(model,optimizer)\n",
    "runner.train(train_loader=loader,valid_loader=loader_valid,num_epoch=args['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1/score2 on test set:0.9905299501287883,0.9784304415654888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9905299501287883, 0.9784304415654888)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.predict(test_loader=loader_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on valid set upgraded: accuracy: 0.056304070344631967\n",
      "[epoch]:1,[step]:10,[loss]:787.1118774414062,[score1]:0.8333333333333334,[score2]:0.0\n",
      "Best performance on valid set upgraded: accuracy: 0.25684300099276697\n",
      "Best performance on valid set upgraded: accuracy: 0.3786696922422351\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "[epoch]:1,[step]:20,[loss]:317.7385559082031,[score1]:0.9311348205625606,[score2]:0.4740740740740741\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.39001560062402496\n",
      "Best performance on valid set upgraded: accuracy: 0.3901574244787973\n",
      "Best performance on valid set upgraded: accuracy: 0.3901574244787973\n",
      "Best performance on valid set upgraded: accuracy: 0.3901574244787973\n",
      "Best performance on valid set upgraded: accuracy: 0.3912920153169763\n",
      "Best performance on valid set upgraded: accuracy: 0.3920011345908382\n",
      "Best performance on valid set upgraded: accuracy: 0.3948376116862856\n",
      "Best performance on valid set upgraded: accuracy: 0.399943270458091\n",
      "[epoch]:1,[step]:30,[loss]:211.79037475585938,[score1]:0.9229074889867841,[score2]:0.47761194029850745\n",
      "Best performance on valid set upgraded: accuracy: 0.40972911643738474\n",
      "Best performance on valid set upgraded: accuracy: 0.4199404339809956\n",
      "Best performance on valid set upgraded: accuracy: 0.4372429442632251\n",
      "Best performance on valid set upgraded: accuracy: 0.45695646007658486\n",
      "Best performance on valid set upgraded: accuracy: 0.48844135583605164\n",
      "Best performance on valid set upgraded: accuracy: 0.5200680754502908\n",
      "Best performance on valid set upgraded: accuracy: 0.5524039143383918\n",
      "Best performance on valid set upgraded: accuracy: 0.5881435257410297\n",
      "Best performance on valid set upgraded: accuracy: 0.6230321940150333\n",
      "Best performance on valid set upgraded: accuracy: 0.6505460218408736\n",
      "[epoch]:1,[step]:40,[loss]:148.30540466308594,[score1]:0.9357351509250244,[score2]:0.5895522388059702\n",
      "Best performance on valid set upgraded: accuracy: 0.6738051340235428\n",
      "Best performance on valid set upgraded: accuracy: 0.6933768259821302\n",
      "Best performance on valid set upgraded: accuracy: 0.7135158133598071\n",
      "Best performance on valid set upgraded: accuracy: 0.7342220961565735\n",
      "Best performance on valid set upgraded: accuracy: 0.7530846688412991\n",
      "Best performance on valid set upgraded: accuracy: 0.7709544745426181\n",
      "Best performance on valid set upgraded: accuracy: 0.7837186214721316\n",
      "Best performance on valid set upgraded: accuracy: 0.7918025811941568\n",
      "Best performance on valid set upgraded: accuracy: 0.8049921996879875\n",
      "Best performance on valid set upgraded: accuracy: 0.815061693376826\n",
      "[epoch]:1,[step]:50,[loss]:153.90211486816406,[score1]:0.948948948948949,[score2]:0.7721518987341772\n",
      "Best performance on valid set upgraded: accuracy: 0.8266912494681605\n",
      "Best performance on valid set upgraded: accuracy: 0.8347752091901858\n",
      "Best performance on valid set upgraded: accuracy: 0.8377535101404057\n",
      "Best performance on valid set upgraded: accuracy: 0.8390299248333569\n",
      "Best performance on valid set upgraded: accuracy: 0.8441355836051624\n",
      "[epoch]:1,[step]:60,[loss]:171.93878173828125,[score1]:0.9497863247863247,[score2]:0.7570621468926554\n",
      "Best performance on valid set upgraded: accuracy: 0.8492412423769679\n",
      "Best performance on valid set upgraded: accuracy: 0.8550560204226351\n",
      "Best performance on valid set upgraded: accuracy: 0.8583179690823997\n",
      "Best performance on valid set upgraded: accuracy: 0.8622890370160261\n",
      "Best performance on valid set upgraded: accuracy: 0.8672528719330591\n",
      "Best performance on valid set upgraded: accuracy: 0.8722167068500922\n",
      "Best performance on valid set upgraded: accuracy: 0.8776060133314424\n",
      "Best performance on valid set upgraded: accuracy: 0.8839880867961991\n",
      "Best performance on valid set upgraded: accuracy: 0.8866827400368742\n",
      "[epoch]:1,[step]:70,[loss]:106.36125946044922,[score1]:0.9488536155202821,[score2]:0.8333333333333334\n",
      "Best performance on valid set upgraded: accuracy: 0.8875336831655084\n",
      "Best performance on valid set upgraded: accuracy: 0.8888100978584598\n",
      "Best performance on valid set upgraded: accuracy: 0.8900865125514111\n",
      "Best performance on valid set upgraded: accuracy: 0.8937739327754929\n",
      "Best performance on valid set upgraded: accuracy: 0.8956176428875336\n",
      "[epoch]:1,[step]:80,[loss]:39.59535217285156,[score1]:0.9826800364630811,[score2]:0.8666666666666667\n",
      "Best performance on valid set upgraded: accuracy: 0.8985959438377535\n",
      "Best performance on valid set upgraded: accuracy: 0.9049780173025103\n",
      "Best performance on valid set upgraded: accuracy: 0.9103673237838604\n",
      "Best performance on valid set upgraded: accuracy: 0.914763863281804\n",
      "Best performance on valid set upgraded: accuracy: 0.9154729825556659\n",
      "Best performance on valid set upgraded: accuracy: 0.9154729825556659\n",
      "Best performance on valid set upgraded: accuracy: 0.9171748688129343\n",
      "Best performance on valid set upgraded: accuracy: 0.9174585165224791\n",
      "Best performance on valid set upgraded: accuracy: 0.9183094596511133\n",
      "[epoch]:1,[step]:90,[loss]:76.37979125976562,[score1]:0.9631956912028725,[score2]:0.8764705882352941\n",
      "Best performance on valid set upgraded: accuracy: 0.9208622890370161\n",
      "[epoch]:1,[step]:100,[loss]:116.9563217163086,[score1]:0.9486673247778875,[score2]:0.7806122448979592\n",
      "Best performance on valid set upgraded: accuracy: 0.9235569422776911\n",
      "Best performance on valid set upgraded: accuracy: 0.9262515955183662\n",
      "[epoch]:1,[step]:110,[loss]:77.01197814941406,[score1]:0.9747191011235955,[score2]:0.82\n",
      "Best performance on valid set upgraded: accuracy: 0.9297971918876755\n",
      "Best performance on valid set upgraded: accuracy: 0.9346192029499362\n",
      "Best performance on valid set upgraded: accuracy: 0.9356119699333428\n",
      "[epoch]:1,[step]:120,[loss]:64.42256927490234,[score1]:0.974025974025974,[score2]:0.9056603773584906\n",
      "[epoch]:1,[step]:130,[loss]:80.73668670654297,[score1]:0.9696682464454977,[score2]:0.8154761904761905\n",
      "Best performance on valid set upgraded: accuracy: 0.9371720323358389\n",
      "Best performance on valid set upgraded: accuracy: 0.9373138561906112\n",
      "Best performance on valid set upgraded: accuracy: 0.9375975039001561\n",
      "Best performance on valid set upgraded: accuracy: 0.9384484470287903\n",
      "Best performance on valid set upgraded: accuracy: 0.9404339809956035\n",
      "Best performance on valid set upgraded: accuracy: 0.9429868103815062\n",
      "Best performance on valid set upgraded: accuracy: 0.9446886966387746\n",
      "Best performance on valid set upgraded: accuracy: 0.9456814636221812\n",
      "Best performance on valid set upgraded: accuracy: 0.945965111331726\n",
      "[epoch]:1,[step]:140,[loss]:25.98668670654297,[score1]:0.9893390191897654,[score2]:0.9658119658119658\n",
      "[epoch]:1,[step]:150,[loss]:42.23236083984375,[score1]:0.9829443447037702,[score2]:0.9263803680981595\n",
      "Best performance on valid set upgraded: accuracy: 0.9462487590412707\n",
      "Best performance on valid set upgraded: accuracy: 0.9483761168628563\n",
      "Best performance on valid set upgraded: accuracy: 0.950503474684442\n",
      "Best performance on valid set upgraded: accuracy: 0.9519217132321657\n",
      "Best performance on valid set upgraded: accuracy: 0.9523471847964827\n",
      "[epoch]:1,[step]:160,[loss]:41.271392822265625,[score1]:0.9720616570327553,[score2]:0.9090909090909091\n",
      "[epoch]:1,[step]:170,[loss]:61.53343963623047,[score1]:0.9763617677286742,[score2]:0.8972972972972973\n",
      "Best performance on valid set upgraded: accuracy: 0.9547581903276131\n",
      "Best performance on valid set upgraded: accuracy: 0.9573110197135158\n",
      "Best performance on valid set upgraded: accuracy: 0.9590129059707843\n",
      "[epoch]:1,[step]:180,[loss]:60.631980895996094,[score1]:0.9691011235955056,[score2]:0.8878923766816144\n",
      "[epoch]:1,[step]:190,[loss]:58.11067199707031,[score1]:0.9701789264413518,[score2]:0.8768115942028986\n",
      "[epoch]:1,[step]:200,[loss]:50.34912872314453,[score1]:0.9825918762088974,[score2]:0.92018779342723\n",
      "[epoch]:1,[step]:210,[loss]:61.326637268066406,[score1]:0.958139534883721,[score2]:0.8732394366197183\n",
      "[epoch]:1,[step]:220,[loss]:29.911361694335938,[score1]:0.9793427230046948,[score2]:0.9436619718309859\n",
      "[epoch]:1,[step]:230,[loss]:49.12334442138672,[score1]:0.9762773722627737,[score2]:0.8955223880597015\n",
      "[epoch]:1,[step]:240,[loss]:58.183868408203125,[score1]:0.9733333333333334,[score2]:0.8661971830985915\n",
      "Best performance on valid set upgraded: accuracy: 0.9591547298255566\n",
      "Best performance on valid set upgraded: accuracy: 0.9598638490994186\n",
      "[epoch]:1,[step]:250,[loss]:55.147552490234375,[score1]:0.9731876861966237,[score2]:0.8455882352941176\n",
      "[epoch]:1,[step]:260,[loss]:46.68567657470703,[score1]:0.9740980573543015,[score2]:0.8628571428571429\n",
      "Best performance on valid set upgraded: accuracy: 0.9602893206637356\n",
      "Best performance on valid set upgraded: accuracy: 0.9619912069210041\n",
      "Best performance on valid set upgraded: accuracy: 0.9625585023400937\n",
      "Best performance on valid set upgraded: accuracy: 0.962700326194866\n",
      "[epoch]:1,[step]:270,[loss]:27.34320068359375,[score1]:0.9957894736842106,[score2]:0.9705882352941176\n",
      "[epoch]:1,[step]:280,[loss]:37.87269592285156,[score1]:0.98545101842871,[score2]:0.9420289855072463\n",
      "[epoch]:1,[step]:290,[loss]:36.53739929199219,[score1]:0.9816700610997964,[score2]:0.8987341772151899\n",
      "Best performance on valid set upgraded: accuracy: 0.963125797759183\n",
      "[epoch]:1,[step]:300,[loss]:64.68885040283203,[score1]:0.9701492537313433,[score2]:0.84375\n",
      "Best performance on valid set upgraded: accuracy: 0.9648276840164516\n",
      "[epoch]:1,[step]:310,[loss]:44.917205810546875,[score1]:0.9723320158102767,[score2]:0.8536585365853658\n",
      "Best performance on valid set upgraded: accuracy: 0.966104098709403\n",
      "Best performance on valid set upgraded: accuracy: 0.9668132179832648\n",
      "[epoch]:1,[step]:320,[loss]:49.45545196533203,[score1]:0.9807507218479307,[score2]:0.9226519337016574\n",
      "[epoch]:1,[step]:330,[loss]:43.384124755859375,[score1]:0.9707661290322581,[score2]:0.896774193548387\n",
      "[epoch]:1,[step]:340,[loss]:22.377357482910156,[score1]:0.9825819672131147,[score2]:0.8898305084745762\n",
      "[epoch]:1,[step]:350,[loss]:27.832191467285156,[score1]:0.9888059701492538,[score2]:0.9774011299435028\n",
      "Best performance on valid set upgraded: accuracy: 0.9675223372571267\n",
      "Best performance on valid set upgraded: accuracy: 0.968798751950078\n",
      "[epoch]:1,[step]:360,[loss]:24.456947326660156,[score1]:0.9828734538534729,[score2]:0.9325842696629213\n",
      "Best performance on valid set upgraded: accuracy: 0.9709261097716636\n",
      "Best performance on valid set upgraded: accuracy: 0.9717770529002978\n",
      "Best performance on valid set upgraded: accuracy: 0.9727698198837045\n",
      "Best performance on valid set upgraded: accuracy: 0.9733371153027939\n",
      "[epoch]:1,[step]:370,[loss]:75.61479187011719,[score1]:0.9713261648745519,[score2]:0.875\n",
      "[epoch]:1,[step]:380,[loss]:20.132339477539062,[score1]:0.9923809523809524,[score2]:0.9407407407407408\n",
      "[epoch]:1,[step]:390,[loss]:24.540771484375,[score1]:0.9941916747337851,[score2]:0.9625\n",
      "[epoch]:2,[step]:400,[loss]:15.472061157226562,[score1]:0.9968847352024922,[score2]:0.9797297297297297\n",
      "[epoch]:2,[step]:410,[loss]:9.451850891113281,[score1]:0.9908814589665653,[score2]:0.9557522123893806\n",
      "[epoch]:2,[step]:420,[loss]:19.64361572265625,[score1]:0.9902152641878669,[score2]:0.9565217391304348\n",
      "[epoch]:2,[step]:430,[loss]:7.77557373046875,[score1]:0.9893307468477207,[score2]:0.9056603773584906\n",
      "[epoch]:2,[step]:440,[loss]:43.58357620239258,[score1]:0.9775070290534208,[score2]:0.9175257731958762\n",
      "[epoch]:2,[step]:450,[loss]:20.53826904296875,[score1]:0.9871205151793928,[score2]:0.9672897196261683\n",
      "[epoch]:2,[step]:460,[loss]:15.980941772460938,[score1]:0.994263862332696,[score2]:0.9653179190751445\n",
      "[epoch]:2,[step]:470,[loss]:44.100250244140625,[score1]:0.9868305531167691,[score2]:0.9330143540669856\n",
      "[epoch]:2,[step]:480,[loss]:21.034561157226562,[score1]:0.9854576561163387,[score2]:0.9314285714285714\n",
      "[epoch]:2,[step]:490,[loss]:35.80015563964844,[score1]:0.9855630413859481,[score2]:0.918918918918919\n",
      "[epoch]:2,[step]:500,[loss]:27.744232177734375,[score1]:0.9853211009174312,[score2]:0.9407894736842105\n",
      "[epoch]:2,[step]:510,[loss]:10.158615112304688,[score1]:0.989786443825441,[score2]:0.9842105263157894\n",
      "[epoch]:2,[step]:520,[loss]:25.388832092285156,[score1]:0.9881188118811881,[score2]:0.9205298013245033\n",
      "[epoch]:2,[step]:530,[loss]:12.183578491210938,[score1]:0.987535953978907,[score2]:0.975\n",
      "[epoch]:2,[step]:540,[loss]:15.345657348632812,[score1]:0.9868554095045501,[score2]:0.9457831325301205\n",
      "[epoch]:2,[step]:550,[loss]:37.66996765136719,[score1]:0.9799398194583752,[score2]:0.9044117647058824\n",
      "[epoch]:2,[step]:560,[loss]:7.76873779296875,[score1]:0.9961685823754789,[score2]:0.9866666666666667\n",
      "[epoch]:2,[step]:570,[loss]:19.37274169921875,[score1]:0.992633517495396,[score2]:0.9807692307692307\n",
      "[epoch]:2,[step]:580,[loss]:18.259613037109375,[score1]:0.9779270633397313,[score2]:0.9013157894736842\n",
      "[epoch]:2,[step]:590,[loss]:12.647407531738281,[score1]:0.9898785425101214,[score2]:0.96\n",
      "[epoch]:2,[step]:600,[loss]:8.066635131835938,[score1]:0.9919110212335692,[score2]:0.948051948051948\n",
      "Best performance on valid set upgraded: accuracy: 0.9736207630123387\n",
      "Best performance on valid set upgraded: accuracy: 0.9736207630123387\n",
      "[epoch]:2,[step]:610,[loss]:39.61963653564453,[score1]:0.986021505376344,[score2]:0.9153846153846154\n",
      "[epoch]:2,[step]:620,[loss]:11.721656799316406,[score1]:0.9867211440245148,[score2]:0.9345238095238095\n",
      "[epoch]:2,[step]:630,[loss]:18.436302185058594,[score1]:0.9801390268123138,[score2]:0.9701492537313433\n",
      "[epoch]:2,[step]:640,[loss]:20.810821533203125,[score1]:0.9903339191564148,[score2]:0.9457831325301205\n",
      "[epoch]:2,[step]:650,[loss]:30.497299194335938,[score1]:0.9831460674157303,[score2]:0.927536231884058\n",
      "[epoch]:2,[step]:660,[loss]:35.39598083496094,[score1]:0.9768844221105528,[score2]:0.9171270718232044\n",
      "[epoch]:2,[step]:670,[loss]:14.060943603515625,[score1]:0.9897388059701493,[score2]:0.9261744966442953\n",
      "Best performance on valid set upgraded: accuracy: 0.9736207630123387\n",
      "Best performance on valid set upgraded: accuracy: 0.9739044107218834\n",
      "[epoch]:2,[step]:680,[loss]:21.389236450195312,[score1]:0.9918032786885246,[score2]:0.96875\n",
      "[epoch]:2,[step]:690,[loss]:15.198150634765625,[score1]:0.9956178790534619,[score2]:0.9722222222222222\n",
      "[epoch]:2,[step]:700,[loss]:14.12738037109375,[score1]:0.9903194578896418,[score2]:0.9725274725274725\n",
      "[epoch]:2,[step]:710,[loss]:24.698455810546875,[score1]:0.9804305283757339,[score2]:0.9509803921568627\n",
      "Best performance on valid set upgraded: accuracy: 0.9740462345766558\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "Best performance on valid set upgraded: accuracy: 0.97489717770529\n",
      "[epoch]:2,[step]:720,[loss]:25.20136260986328,[score1]:0.983739837398374,[score2]:0.9779005524861878\n",
      "[epoch]:2,[step]:730,[loss]:18.811416625976562,[score1]:0.9884169884169884,[score2]:0.9426751592356688\n",
      "Best performance on valid set upgraded: accuracy: 0.9751808254148348\n",
      "[epoch]:2,[step]:740,[loss]:7.7935638427734375,[score1]:0.9892262487757101,[score2]:0.9621212121212122\n",
      "[epoch]:2,[step]:750,[loss]:6.1563262939453125,[score1]:0.994088669950739,[score2]:0.9673202614379085\n",
      "[epoch]:2,[step]:760,[loss]:39.19624328613281,[score1]:0.9738766980146291,[score2]:0.8802395209580839\n",
      "[epoch]:2,[step]:770,[loss]:21.62079620361328,[score1]:0.9899175068744271,[score2]:0.9767441860465116\n",
      "[epoch]:2,[step]:780,[loss]:5.79339599609375,[score1]:0.990909090909091,[score2]:0.9741379310344828\n",
      "[epoch]:3,[step]:790,[loss]:13.1324462890625,[score1]:0.988011988011988,[score2]:0.9299363057324841\n",
      "[epoch]:3,[step]:800,[loss]:17.53717041015625,[score1]:0.9878957169459963,[score2]:0.9261363636363636\n",
      "[epoch]:3,[step]:810,[loss]:6.2824554443359375,[score1]:0.9917506874427131,[score2]:0.9603174603174603\n",
      "[epoch]:3,[step]:820,[loss]:3.997894287109375,[score1]:0.993601462522852,[score2]:0.9602272727272727\n",
      "[epoch]:3,[step]:830,[loss]:23.614883422851562,[score1]:0.9868544600938968,[score2]:0.945\n",
      "[epoch]:3,[step]:840,[loss]:16.554397583007812,[score1]:0.9877010406811731,[score2]:0.9482758620689655\n",
      "[epoch]:3,[step]:850,[loss]:4.874847412109375,[score1]:0.9910979228486647,[score2]:1.0\n",
      "[epoch]:3,[step]:860,[loss]:5.4799346923828125,[score1]:0.9927206551410374,[score2]:0.9805194805194806\n",
      "[epoch]:3,[step]:870,[loss]:12.9481201171875,[score1]:0.9904489016236867,[score2]:0.9583333333333334\n",
      "[epoch]:3,[step]:880,[loss]:10.054229736328125,[score1]:0.9904852521408183,[score2]:0.9492753623188406\n",
      "Best performance on valid set upgraded: accuracy: 0.9753226492696071\n",
      "Best performance on valid set upgraded: accuracy: 0.9756062969791519\n",
      "[epoch]:3,[step]:890,[loss]:10.275436401367188,[score1]:0.9902152641878669,[score2]:0.9634146341463414\n",
      "[epoch]:3,[step]:900,[loss]:6.2692413330078125,[score1]:0.9885496183206107,[score2]:0.9225352112676056\n",
      "[epoch]:3,[step]:910,[loss]:4.394561767578125,[score1]:0.9891625615763546,[score2]:0.9523809523809523\n",
      "[epoch]:3,[step]:920,[loss]:6.8360748291015625,[score1]:0.9901283316880553,[score2]:0.9575471698113207\n",
      "[epoch]:3,[step]:930,[loss]:7.877082824707031,[score1]:0.9962264150943396,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9756062969791519\n",
      "[epoch]:3,[step]:940,[loss]:8.85430908203125,[score1]:0.9962406015037594,[score2]:0.972027972027972\n",
      "[epoch]:3,[step]:950,[loss]:2.286224365234375,[score1]:0.9981185324553151,[score2]:0.990909090909091\n",
      "[epoch]:3,[step]:960,[loss]:21.82280731201172,[score1]:0.9924953095684803,[score2]:0.9542857142857143\n",
      "Best performance on valid set upgraded: accuracy: 0.976031768543469\n",
      "Best performance on valid set upgraded: accuracy: 0.9764572401077861\n",
      "[epoch]:3,[step]:970,[loss]:4.489837646484375,[score1]:0.9955516014234875,[score2]:0.9735099337748344\n",
      "[epoch]:3,[step]:980,[loss]:8.344009399414062,[score1]:0.9971098265895953,[score2]:0.9848484848484849\n",
      "[epoch]:3,[step]:990,[loss]:6.9621429443359375,[score1]:0.9878618113912232,[score2]:0.9266666666666666\n",
      "[epoch]:3,[step]:1000,[loss]:16.91265869140625,[score1]:0.9905749293119699,[score2]:0.9714285714285714\n",
      "[epoch]:3,[step]:1010,[loss]:7.858589172363281,[score1]:0.9920318725099602,[score2]:0.9745222929936306\n",
      "[epoch]:3,[step]:1020,[loss]:17.862838745117188,[score1]:0.9924314096499527,[score2]:0.9553072625698324\n",
      "[epoch]:3,[step]:1030,[loss]:10.852828979492188,[score1]:0.9881889763779528,[score2]:0.948936170212766\n",
      "[epoch]:3,[step]:1040,[loss]:16.263267517089844,[score1]:0.986870897155361,[score2]:0.9470588235294117\n",
      "[epoch]:3,[step]:1050,[loss]:3.21832275390625,[score1]:0.9940828402366864,[score2]:0.9640718562874252\n",
      "Best performance on valid set upgraded: accuracy: 0.9767408878173309\n",
      "[epoch]:3,[step]:1060,[loss]:12.270576477050781,[score1]:0.9919678714859438,[score2]:0.9655172413793104\n",
      "[epoch]:3,[step]:1070,[loss]:9.23974609375,[score1]:0.989443378119002,[score2]:0.9407894736842105\n",
      "[epoch]:3,[step]:1080,[loss]:16.223068237304688,[score1]:0.9971804511278195,[score2]:0.9846153846153847\n",
      "[epoch]:3,[step]:1090,[loss]:12.380805969238281,[score1]:0.9919678714859438,[score2]:0.9615384615384616\n",
      "[epoch]:3,[step]:1100,[loss]:10.06689453125,[score1]:0.996135265700483,[score2]:0.9852216748768473\n",
      "[epoch]:3,[step]:1110,[loss]:15.158935546875,[score1]:0.9897388059701493,[score2]:0.9692307692307692\n",
      "[epoch]:3,[step]:1120,[loss]:2.5837249755859375,[score1]:0.9912451361867705,[score2]:0.975609756097561\n",
      "[epoch]:3,[step]:1130,[loss]:6.66485595703125,[score1]:0.9963133640552996,[score2]:0.9682539682539683\n",
      "[epoch]:3,[step]:1140,[loss]:13.656021118164062,[score1]:0.984552008238929,[score2]:0.9513513513513514\n",
      "[epoch]:3,[step]:1150,[loss]:36.54408264160156,[score1]:0.9723046488625123,[score2]:0.8712871287128713\n",
      "[epoch]:3,[step]:1160,[loss]:6.0819244384765625,[score1]:0.9960356788899901,[score2]:0.9736842105263158\n",
      "[epoch]:3,[step]:1170,[loss]:23.81926727294922,[score1]:0.9866793529971456,[score2]:0.9526627218934911\n",
      "[epoch]:3,[step]:1180,[loss]:19.585403442382812,[score1]:0.9837606837606837,[score2]:0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from FGM import FGM\n",
    "model = NERModel()\n",
    "model.to(device)\n",
    "fgm = FGM(model=model)\n",
    "optimizer = AdamW(model.parameters(), lr=args['init_lr']) \n",
    "runner = NER_Runner_FGM(model,optimizer,fgm = fgm)\n",
    "runner.train(train_loader=loader,valid_loader=loader_valid,num_epoch=args['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1/score2 on test set:0.9922617416561627,0.9763277487621244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9922617416561627, 0.9763277487621244)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.predict(test_loader=loader_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on valid set upgraded: accuracy: 0.08239965962274855\n",
      "[epoch]:1,[step]:10,[loss]:836.404541015625,[score1]:0.7948979591836735,[score2]:0.0\n",
      "Best performance on valid set upgraded: accuracy: 0.17486881293433557\n",
      "Best performance on valid set upgraded: accuracy: 0.3642036590554531\n",
      "Best performance on valid set upgraded: accuracy: 0.38803006665721174\n",
      "Best performance on valid set upgraded: accuracy: 0.3901574244787973\n",
      "Best performance on valid set upgraded: accuracy: 0.39412849241242376\n",
      "Best performance on valid set upgraded: accuracy: 0.4003687420224082\n",
      "Best performance on valid set upgraded: accuracy: 0.4085945255992058\n",
      "[epoch]:1,[step]:20,[loss]:443.4123840332031,[score1]:0.8960674157303371,[score2]:0.367816091954023\n",
      "Best performance on valid set upgraded: accuracy: 0.41823854772372715\n",
      "Best performance on valid set upgraded: accuracy: 0.42646433130052475\n",
      "Best performance on valid set upgraded: accuracy: 0.43213728549141966\n",
      "Best performance on valid set upgraded: accuracy: 0.4397957736491278\n",
      "Best performance on valid set upgraded: accuracy: 0.44461778471138846\n",
      "Best performance on valid set upgraded: accuracy: 0.4497234434831939\n",
      "Best performance on valid set upgraded: accuracy: 0.45709828393135726\n",
      "Best performance on valid set upgraded: accuracy: 0.4664586583463339\n",
      "Best performance on valid set upgraded: accuracy: 0.4789391575663027\n",
      "Best performance on valid set upgraded: accuracy: 0.49198695220536093\n",
      "[epoch]:1,[step]:30,[loss]:324.03155517578125,[score1]:0.8859649122807017,[score2]:0.4090909090909091\n",
      "Best performance on valid set upgraded: accuracy: 0.5151042405332577\n",
      "Best performance on valid set upgraded: accuracy: 0.536519642603886\n",
      "Best performance on valid set upgraded: accuracy: 0.5627570557367749\n",
      "Best performance on valid set upgraded: accuracy: 0.5936746560771522\n",
      "Best performance on valid set upgraded: accuracy: 0.6258686711104808\n",
      "Best performance on valid set upgraded: accuracy: 0.6545170897745001\n",
      "Best performance on valid set upgraded: accuracy: 0.6804708551978442\n",
      "Best performance on valid set upgraded: accuracy: 0.710821160119132\n",
      "Best performance on valid set upgraded: accuracy: 0.7335129768827117\n",
      "Best performance on valid set upgraded: accuracy: 0.753793788115161\n",
      "[epoch]:1,[step]:40,[loss]:230.46847534179688,[score1]:0.9320987654320988,[score2]:0.6630434782608695\n",
      "Best performance on valid set upgraded: accuracy: 0.772089065380797\n",
      "Best performance on valid set upgraded: accuracy: 0.7845695646007659\n",
      "Best performance on valid set upgraded: accuracy: 0.7932208197418806\n",
      "Best performance on valid set upgraded: accuracy: 0.8027230180116296\n",
      "Best performance on valid set upgraded: accuracy: 0.8110906254431995\n",
      "Best performance on valid set upgraded: accuracy: 0.8147780456672813\n",
      "Best performance on valid set upgraded: accuracy: 0.8194582328747695\n",
      "Best performance on valid set upgraded: accuracy: 0.8220110622606722\n",
      "Best performance on valid set upgraded: accuracy: 0.8252730109204368\n",
      "Best performance on valid set upgraded: accuracy: 0.825698482484754\n",
      "[epoch]:1,[step]:50,[loss]:163.00125122070312,[score1]:0.9563894523326572,[score2]:0.8131868131868132\n",
      "Best performance on valid set upgraded: accuracy: 0.8264076017586158\n",
      "Best performance on valid set upgraded: accuracy: 0.82725854488725\n",
      "Best performance on valid set upgraded: accuracy: 0.828393135725429\n",
      "Best performance on valid set upgraded: accuracy: 0.8332151467876897\n",
      "Best performance on valid set upgraded: accuracy: 0.8349170330449581\n",
      "Best performance on valid set upgraded: accuracy: 0.8486739469578783\n",
      "Best performance on valid set upgraded: accuracy: 0.8617217415969366\n",
      "Best performance on valid set upgraded: accuracy: 0.8678201673521486\n",
      "Best performance on valid set upgraded: accuracy: 0.8722167068500922\n",
      "Best performance on valid set upgraded: accuracy: 0.8754786555098567\n",
      "[epoch]:1,[step]:60,[loss]:93.02045440673828,[score1]:0.9663699307616221,[score2]:0.8418367346938775\n",
      "Best performance on valid set upgraded: accuracy: 0.8783151326053042\n",
      "Best performance on valid set upgraded: accuracy: 0.8818607289746135\n",
      "Best performance on valid set upgraded: accuracy: 0.884697206070061\n",
      "Best performance on valid set upgraded: accuracy: 0.8863990923273295\n",
      "Best performance on valid set upgraded: accuracy: 0.8882428024393703\n",
      "[epoch]:1,[step]:70,[loss]:111.08804321289062,[score1]:0.9579667644183774,[score2]:0.8235294117647058\n",
      "Best performance on valid set upgraded: accuracy: 0.8895192171323216\n",
      "Best performance on valid set upgraded: accuracy: 0.896468586016168\n",
      "Best performance on valid set upgraded: accuracy: 0.9019997163522905\n",
      "Best performance on valid set upgraded: accuracy: 0.9071053751240958\n",
      "Best performance on valid set upgraded: accuracy: 0.9112182669124946\n",
      "Best performance on valid set upgraded: accuracy: 0.914763863281804\n",
      "Best performance on valid set upgraded: accuracy: 0.9167493972486173\n",
      "[epoch]:1,[step]:80,[loss]:92.3778076171875,[score1]:0.9745347698334965,[score2]:0.9222797927461139\n",
      "Best performance on valid set upgraded: accuracy: 0.9191604027797475\n",
      "Best performance on valid set upgraded: accuracy: 0.9222805275847398\n",
      "[epoch]:1,[step]:90,[loss]:25.61609649658203,[score1]:0.9912621359223301,[score2]:0.9512195121951219\n",
      "Best performance on valid set upgraded: accuracy: 0.9262515955183662\n",
      "Best performance on valid set upgraded: accuracy: 0.9279534817756346\n",
      "Best performance on valid set upgraded: accuracy: 0.9289462487590413\n",
      "Best performance on valid set upgraded: accuracy: 0.9299390157424479\n",
      "Best performance on valid set upgraded: accuracy: 0.9316409019997164\n",
      "Best performance on valid set upgraded: accuracy: 0.9323500212735782\n",
      "[epoch]:1,[step]:100,[loss]:108.26715087890625,[score1]:0.9782608695652174,[score2]:0.9065934065934066\n",
      "Best performance on valid set upgraded: accuracy: 0.9385902708835626\n",
      "Best performance on valid set upgraded: accuracy: 0.9415685718337824\n",
      "Best performance on valid set upgraded: accuracy: 0.9435541058005956\n",
      "[epoch]:1,[step]:110,[loss]:89.50650024414062,[score1]:0.9710669077757685,[score2]:0.895397489539749\n",
      "Best performance on valid set upgraded: accuracy: 0.9439795773649128\n",
      "[epoch]:1,[step]:120,[loss]:51.79084014892578,[score1]:0.9700598802395209,[score2]:0.8524590163934426\n",
      "Best performance on valid set upgraded: accuracy: 0.9468160544603602\n",
      "Best performance on valid set upgraded: accuracy: 0.9479506452985392\n",
      "[epoch]:1,[step]:130,[loss]:150.00852966308594,[score1]:0.9629963898916968,[score2]:0.8795180722891566\n",
      "[epoch]:1,[step]:140,[loss]:52.32304382324219,[score1]:0.9831460674157303,[score2]:0.9523809523809523\n",
      "[epoch]:1,[step]:150,[loss]:48.37486267089844,[score1]:0.986734693877551,[score2]:0.9403669724770642\n",
      "Best performance on valid set upgraded: accuracy: 0.9488015884271734\n",
      "Best performance on valid set upgraded: accuracy: 0.9495107077010353\n",
      "Best performance on valid set upgraded: accuracy: 0.9499361792653525\n",
      "[epoch]:1,[step]:160,[loss]:50.07121276855469,[score1]:0.9852941176470589,[score2]:0.9719101123595506\n",
      "[epoch]:1,[step]:170,[loss]:56.59230041503906,[score1]:0.9816326530612245,[score2]:0.9349112426035503\n",
      "Best performance on valid set upgraded: accuracy: 0.9507871223939867\n",
      "Best performance on valid set upgraded: accuracy: 0.9547581903276131\n",
      "Best performance on valid set upgraded: accuracy: 0.9564600765848815\n",
      "Best performance on valid set upgraded: accuracy: 0.957027372003971\n",
      "Best performance on valid set upgraded: accuracy: 0.9583037866969224\n",
      "[epoch]:1,[step]:180,[loss]:56.442176818847656,[score1]:0.9824380165289256,[score2]:0.9424083769633508\n",
      "[epoch]:1,[step]:190,[loss]:41.25221252441406,[score1]:0.9906716417910447,[score2]:0.9411764705882353\n",
      "[epoch]:1,[step]:200,[loss]:94.08799743652344,[score1]:0.9638095238095238,[score2]:0.8512820512820513\n",
      "Best performance on valid set upgraded: accuracy: 0.9594383775351014\n",
      "[epoch]:1,[step]:210,[loss]:21.080810546875,[score1]:0.9936974789915967,[score2]:0.9612903225806452\n",
      "[epoch]:1,[step]:220,[loss]:43.37358093261719,[score1]:0.9849397590361446,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9595802013898738\n",
      "Best performance on valid set upgraded: accuracy: 0.9597220252446461\n",
      "[epoch]:1,[step]:230,[loss]:27.207809448242188,[score1]:0.9933396764985728,[score2]:0.9559748427672956\n",
      "Best performance on valid set upgraded: accuracy: 0.9624166784853212\n",
      "Best performance on valid set upgraded: accuracy: 0.9645440363069068\n",
      "Best performance on valid set upgraded: accuracy: 0.9675223372571267\n",
      "Best performance on valid set upgraded: accuracy: 0.9685151042405332\n",
      "Best performance on valid set upgraded: accuracy: 0.9689405758048504\n",
      "[epoch]:1,[step]:240,[loss]:54.64739990234375,[score1]:0.9894128970163619,[score2]:0.9874213836477987\n",
      "[epoch]:1,[step]:250,[loss]:33.35894012451172,[score1]:0.9857397504456328,[score2]:0.9285714285714286\n",
      "[epoch]:1,[step]:260,[loss]:41.36643981933594,[score1]:0.9918256130790191,[score2]:0.9545454545454546\n",
      "[epoch]:1,[step]:270,[loss]:25.725616455078125,[score1]:0.9915730337078652,[score2]:0.9436619718309859\n",
      "[epoch]:1,[step]:280,[loss]:62.571006774902344,[score1]:0.9800947867298578,[score2]:0.9328859060402684\n",
      "[epoch]:1,[step]:290,[loss]:20.59539794921875,[score1]:0.9873540856031129,[score2]:0.9621212121212122\n",
      "Best performance on valid set upgraded: accuracy: 0.9695078712239399\n",
      "Best performance on valid set upgraded: accuracy: 0.9697915189334846\n",
      "[epoch]:1,[step]:300,[loss]:86.06428527832031,[score1]:0.9639222941720629,[score2]:0.8591549295774648\n",
      "[epoch]:1,[step]:310,[loss]:30.53778076171875,[score1]:0.9846889952153111,[score2]:0.9080459770114943\n",
      "[epoch]:1,[step]:320,[loss]:36.711334228515625,[score1]:0.9897674418604652,[score2]:0.9870967741935484\n",
      "[epoch]:1,[step]:330,[loss]:52.49501037597656,[score1]:0.9850448654037887,[score2]:0.9230769230769231\n",
      "[epoch]:1,[step]:340,[loss]:23.533660888671875,[score1]:0.9830866807610994,[score2]:0.9235668789808917\n",
      "[epoch]:1,[step]:350,[loss]:21.376052856445312,[score1]:0.9918781725888325,[score2]:0.9523809523809523\n",
      "[epoch]:1,[step]:360,[loss]:30.198448181152344,[score1]:0.9912621359223301,[score2]:0.974025974025974\n",
      "[epoch]:1,[step]:370,[loss]:37.64337158203125,[score1]:0.9849340866290018,[score2]:0.9176470588235294\n",
      "Best performance on valid set upgraded: accuracy: 0.9699333427882569\n",
      "Best performance on valid set upgraded: accuracy: 0.9720607006098426\n",
      "[epoch]:1,[step]:380,[loss]:22.404930114746094,[score1]:0.9896907216494846,[score2]:0.9485714285714286\n",
      "[epoch]:1,[step]:390,[loss]:21.75048065185547,[score1]:0.9811133200795229,[score2]:0.954248366013072\n",
      "[epoch]:2,[step]:400,[loss]:46.72015380859375,[score1]:0.9888991674375578,[score2]:0.9393939393939394\n",
      "[epoch]:2,[step]:410,[loss]:16.274986267089844,[score1]:0.9946751863684771,[score2]:0.9818181818181818\n",
      "[epoch]:2,[step]:420,[loss]:28.079666137695312,[score1]:0.9912663755458515,[score2]:0.9680365296803652\n",
      "[epoch]:2,[step]:430,[loss]:40.17781066894531,[score1]:0.9837728194726166,[score2]:0.9368421052631579\n",
      "Best performance on valid set upgraded: accuracy: 0.9730534675932492\n",
      "Best performance on valid set upgraded: accuracy: 0.9730534675932492\n",
      "Best performance on valid set upgraded: accuracy: 0.9734789391575663\n",
      "[epoch]:2,[step]:440,[loss]:10.967758178710938,[score1]:0.9898242368177613,[score2]:0.9660194174757282\n",
      "[epoch]:2,[step]:450,[loss]:19.772994995117188,[score1]:0.9952107279693486,[score2]:0.9896373056994818\n",
      "[epoch]:2,[step]:460,[loss]:29.896194458007812,[score1]:0.994,[score2]:0.9617834394904459\n",
      "[epoch]:2,[step]:470,[loss]:11.022590637207031,[score1]:0.9946466809421841,[score2]:0.9927536231884058\n",
      "[epoch]:2,[step]:480,[loss]:23.180801391601562,[score1]:0.9880478087649402,[score2]:0.9256756756756757\n",
      "Best performance on valid set upgraded: accuracy: 0.9740462345766558\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "[epoch]:2,[step]:490,[loss]:12.6378173828125,[score1]:0.9887005649717514,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.97489717770529\n",
      "[epoch]:2,[step]:500,[loss]:27.911643981933594,[score1]:0.9899396378269618,[score2]:0.9624413145539906\n",
      "[epoch]:2,[step]:510,[loss]:24.38031005859375,[score1]:0.9916897506925207,[score2]:0.974025974025974\n",
      "[epoch]:2,[step]:520,[loss]:13.286331176757812,[score1]:0.998019801980198,[score2]:0.984251968503937\n",
      "[epoch]:2,[step]:530,[loss]:9.7574462890625,[score1]:0.9960822722820764,[score2]:0.9754601226993865\n",
      "[epoch]:2,[step]:540,[loss]:26.038345336914062,[score1]:0.9927685950413223,[score2]:0.9764705882352941\n",
      "[epoch]:2,[step]:550,[loss]:7.9661712646484375,[score1]:0.996186844613918,[score2]:0.9836065573770492\n",
      "[epoch]:2,[step]:560,[loss]:13.851287841796875,[score1]:0.9925163704396632,[score2]:0.993006993006993\n",
      "[epoch]:2,[step]:570,[loss]:21.009506225585938,[score1]:0.9914772727272727,[score2]:0.9560439560439561\n",
      "[epoch]:2,[step]:580,[loss]:6.446662902832031,[score1]:0.9971830985915493,[score2]:0.9926470588235294\n",
      "[epoch]:2,[step]:590,[loss]:64.20317077636719,[score1]:0.984267453294002,[score2]:0.9253731343283582\n",
      "[epoch]:2,[step]:600,[loss]:12.053924560546875,[score1]:0.9964912280701754,[score2]:0.9896373056994818\n",
      "Best performance on valid set upgraded: accuracy: 0.9754644731243796\n",
      "Best performance on valid set upgraded: accuracy: 0.9758899446886966\n",
      "[epoch]:2,[step]:610,[loss]:9.613929748535156,[score1]:0.9981220657276996,[score2]:0.988950276243094\n",
      "[epoch]:2,[step]:620,[loss]:12.326675415039062,[score1]:0.9928571428571429,[score2]:0.967741935483871\n",
      "[epoch]:2,[step]:630,[loss]:32.14030456542969,[score1]:0.9877704609595485,[score2]:0.943502824858757\n",
      "[epoch]:2,[step]:640,[loss]:9.698745727539062,[score1]:0.9921875,[score2]:0.9542857142857143\n",
      "Best performance on valid set upgraded: accuracy: 0.9761735923982414\n",
      "Best performance on valid set upgraded: accuracy: 0.9764572401077861\n",
      "[epoch]:2,[step]:650,[loss]:19.328216552734375,[score1]:0.9929292929292929,[score2]:0.9444444444444444\n",
      "[epoch]:2,[step]:660,[loss]:12.804840087890625,[score1]:0.9923736892278361,[score2]:0.9493670886075949\n",
      "[epoch]:2,[step]:670,[loss]:19.1170654296875,[score1]:0.9963800904977376,[score2]:0.9813953488372092\n",
      "[epoch]:2,[step]:680,[loss]:16.974166870117188,[score1]:0.9954296160877514,[score2]:0.9743589743589743\n",
      "[epoch]:2,[step]:690,[loss]:10.766326904296875,[score1]:0.9979317476732161,[score2]:0.9935483870967742\n",
      "[epoch]:2,[step]:700,[loss]:22.073272705078125,[score1]:0.9864016736401674,[score2]:0.9518716577540107\n",
      "[epoch]:2,[step]:710,[loss]:5.740608215332031,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:720,[loss]:26.733924865722656,[score1]:0.9931972789115646,[score2]:0.9696969696969697\n",
      "[epoch]:2,[step]:730,[loss]:13.264114379882812,[score1]:0.9953874538745388,[score2]:0.9709302325581395\n",
      "[epoch]:2,[step]:740,[loss]:15.009445190429688,[score1]:0.9946380697050938,[score2]:0.9782608695652174\n",
      "[epoch]:2,[step]:750,[loss]:10.1888427734375,[score1]:0.9930974978429681,[score2]:0.993421052631579\n",
      "[epoch]:2,[step]:760,[loss]:4.765960693359375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:770,[loss]:24.299453735351562,[score1]:0.9873294346978557,[score2]:0.9752475247524752\n",
      "[epoch]:2,[step]:780,[loss]:22.656417846679688,[score1]:0.9914040114613181,[score2]:0.975\n",
      "Best performance on valid set upgraded: accuracy: 0.9774500070911928\n",
      "Best performance on valid set upgraded: accuracy: 0.9791518933484612\n",
      "Best performance on valid set upgraded: accuracy: 0.9792937172032335\n",
      "Best performance on valid set upgraded: accuracy: 0.979435541058006\n",
      "Best performance on valid set upgraded: accuracy: 0.9797191887675507\n",
      "[epoch]:3,[step]:790,[loss]:15.850692749023438,[score1]:0.9981981981981982,[score2]:0.9953917050691244\n",
      "[epoch]:3,[step]:800,[loss]:7.0254669189453125,[score1]:0.9963436928702011,[score2]:1.0\n",
      "[epoch]:3,[step]:810,[loss]:23.4039306640625,[score1]:0.9955237242614146,[score2]:0.9709302325581395\n",
      "[epoch]:3,[step]:820,[loss]:13.97088623046875,[score1]:0.9953445065176909,[score2]:0.9754901960784313\n",
      "Best performance on valid set upgraded: accuracy: 0.9797191887675507\n",
      "Best performance on valid set upgraded: accuracy: 0.9800028364770954\n",
      "[epoch]:3,[step]:830,[loss]:1.886016845703125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:840,[loss]:3.2619400024414062,[score1]:0.9989806320081549,[score2]:0.9935897435897436\n",
      "[epoch]:3,[step]:850,[loss]:2.0663909912109375,[score1]:0.9989888776541962,[score2]:0.9932432432432432\n",
      "[epoch]:3,[step]:860,[loss]:4.28411865234375,[score1]:0.9971291866028709,[score2]:0.9929577464788732\n",
      "[epoch]:3,[step]:870,[loss]:1.31488037109375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:880,[loss]:5.5706329345703125,[score1]:0.9946091644204852,[score2]:0.9754901960784313\n",
      "[epoch]:3,[step]:890,[loss]:2.115081787109375,[score1]:0.9989858012170385,[score2]:0.9940476190476191\n",
      "[epoch]:3,[step]:900,[loss]:0.9866790771484375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:910,[loss]:5.1188812255859375,[score1]:0.9970617042115573,[score2]:0.9826589595375722\n",
      "[epoch]:3,[step]:920,[loss]:1.5508575439453125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:930,[loss]:1.157806396484375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:940,[loss]:7.247283935546875,[score1]:0.9959100204498977,[score2]:0.9766081871345029\n",
      "[epoch]:3,[step]:950,[loss]:5.1191253662109375,[score1]:0.9990783410138249,[score2]:1.0\n",
      "[epoch]:3,[step]:960,[loss]:6.909423828125,[score1]:0.9971401334604385,[score2]:0.9805194805194806\n",
      "[epoch]:3,[step]:970,[loss]:9.74945068359375,[score1]:0.9981378026070763,[score2]:0.9878048780487805\n",
      "[epoch]:3,[step]:980,[loss]:3.5418548583984375,[score1]:0.9981114258734656,[score2]:0.9875776397515528\n",
      "[epoch]:3,[step]:990,[loss]:9.046768188476562,[score1]:0.9938587512794268,[score2]:0.9748427672955975\n",
      "[epoch]:3,[step]:1000,[loss]:30.649444580078125,[score1]:0.988360814742968,[score2]:0.9659090909090909\n",
      "[epoch]:3,[step]:1010,[loss]:4.576141357421875,[score1]:0.9961904761904762,[score2]:0.9710144927536232\n",
      "[epoch]:3,[step]:1020,[loss]:6.6808013916015625,[score1]:0.99581589958159,[score2]:0.975609756097561\n",
      "[epoch]:3,[step]:1030,[loss]:3.9453125,[score1]:0.9980525803310614,[score2]:0.9933333333333333\n",
      "[epoch]:3,[step]:1040,[loss]:11.676116943359375,[score1]:0.9971181556195965,[score2]:0.9891891891891892\n",
      "[epoch]:3,[step]:1050,[loss]:7.993927001953125,[score1]:0.9930486593843099,[score2]:0.9740932642487047\n",
      "[epoch]:3,[step]:1060,[loss]:19.110565185546875,[score1]:0.9934579439252337,[score2]:0.9788359788359788\n",
      "[epoch]:3,[step]:1070,[loss]:19.63916015625,[score1]:0.9923224568138196,[score2]:1.0\n",
      "[epoch]:3,[step]:1080,[loss]:1.4707794189453125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1090,[loss]:4.356475830078125,[score1]:0.9952335557673975,[score2]:0.9735099337748344\n",
      "[epoch]:3,[step]:1100,[loss]:10.799217224121094,[score1]:0.9935364727608494,[score2]:0.9653465346534653\n",
      "[epoch]:3,[step]:1110,[loss]:4.762939453125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1120,[loss]:25.483230590820312,[score1]:0.992992992992993,[score2]:0.9657534246575342\n",
      "[epoch]:3,[step]:1130,[loss]:7.011505126953125,[score1]:0.9980487804878049,[score2]:0.9863013698630136\n",
      "[epoch]:3,[step]:1140,[loss]:8.921310424804688,[score1]:0.9959839357429718,[score2]:0.9809523809523809\n",
      "[epoch]:3,[step]:1150,[loss]:5.177085876464844,[score1]:0.992936427850656,[score2]:0.9844961240310077\n",
      "[epoch]:3,[step]:1160,[loss]:9.324188232421875,[score1]:0.9990138067061144,[score2]:0.9946808510638298\n",
      "[epoch]:3,[step]:1170,[loss]:5.8704833984375,[score1]:0.9938837920489296,[score2]:0.9627329192546584\n",
      "Best performance on valid set upgraded: accuracy: 0.9802864841866402\n",
      "[epoch]:3,[step]:1180,[loss]:43.52131652832031,[score1]:0.9907407407407407,[score2]:1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from PGD import PGD\n",
    "model = NERModel()\n",
    "model.to(device)\n",
    "pgd = PGD(model=model)\n",
    "optimizer = AdamW(model.parameters(), lr=args['init_lr']) \n",
    "runner = NER_Runner_PGD(model,optimizer,pgd = pgd)\n",
    "runner.train(train_loader=loader,valid_loader=loader_valid,num_epoch=args['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1/score2 on test set:0.9925028771852907,0.9759207759614732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9925028771852907, 0.9759207759614732)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.predict(test_loader=loader_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用FreeLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance on valid set upgraded: accuracy: 0.06623174017869805\n",
      "[epoch]:1,[step]:10,[loss]:581.8079833984375,[score1]:0.8646895273401297,[score2]:0.0\n",
      "Best performance on valid set upgraded: accuracy: 0.07814494397957736\n",
      "Best performance on valid set upgraded: accuracy: 0.1794071762870515\n",
      "Best performance on valid set upgraded: accuracy: 0.19571691958587434\n",
      "Best performance on valid set upgraded: accuracy: 0.22365621897603177\n",
      "Best performance on valid set upgraded: accuracy: 0.3093178272585449\n",
      "Best performance on valid set upgraded: accuracy: 0.36831655084385195\n",
      "Best performance on valid set upgraded: accuracy: 0.3898737767692526\n",
      "Best performance on valid set upgraded: accuracy: 0.3954049071053751\n",
      "Best performance on valid set upgraded: accuracy: 0.3995177988937739\n",
      "[epoch]:1,[step]:20,[loss]:410.32818603515625,[score1]:0.893923789907312,[score2]:0.3855421686746988\n",
      "Best performance on valid set upgraded: accuracy: 0.4095872925826124\n",
      "Best performance on valid set upgraded: accuracy: 0.4210750248191746\n",
      "Best performance on valid set upgraded: accuracy: 0.4351155864416395\n",
      "Best performance on valid set upgraded: accuracy: 0.4488725003545596\n",
      "Best performance on valid set upgraded: accuracy: 0.46177847113884557\n",
      "Best performance on valid set upgraded: accuracy: 0.479080981421075\n",
      "Best performance on valid set upgraded: accuracy: 0.4915614806410438\n",
      "Best performance on valid set upgraded: accuracy: 0.501914622039427\n",
      "Best performance on valid set upgraded: accuracy: 0.5158133598071195\n",
      "Best performance on valid set upgraded: accuracy: 0.53198127925117\n",
      "[epoch]:1,[step]:30,[loss]:193.4656524658203,[score1]:0.9413680781758957,[score2]:0.5859375\n",
      "Best performance on valid set upgraded: accuracy: 0.5481491986952205\n",
      "Best performance on valid set upgraded: accuracy: 0.56545170897745\n",
      "Best performance on valid set upgraded: accuracy: 0.5811941568571833\n",
      "Best performance on valid set upgraded: accuracy: 0.6040277974755354\n",
      "Best performance on valid set upgraded: accuracy: 0.6223230747411714\n",
      "Best performance on valid set upgraded: accuracy: 0.6420365905545312\n",
      "Best performance on valid set upgraded: accuracy: 0.6648702311728832\n",
      "Best performance on valid set upgraded: accuracy: 0.6884129910650971\n",
      "Best performance on valid set upgraded: accuracy: 0.7088356261523188\n",
      "Best performance on valid set upgraded: accuracy: 0.72982555665863\n",
      "[epoch]:1,[step]:40,[loss]:176.7248077392578,[score1]:0.9436475409836066,[score2]:0.696969696969697\n",
      "Best performance on valid set upgraded: accuracy: 0.7447170614097292\n",
      "Best performance on valid set upgraded: accuracy: 0.7611686285633243\n",
      "Best performance on valid set upgraded: accuracy: 0.7719472415260247\n",
      "Best performance on valid set upgraded: accuracy: 0.7814494397957736\n",
      "Best performance on valid set upgraded: accuracy: 0.793362643596653\n",
      "Best performance on valid set upgraded: accuracy: 0.8047085519784428\n",
      "Best performance on valid set upgraded: accuracy: 0.8143525741029641\n",
      "Best performance on valid set upgraded: accuracy: 0.8218692384058999\n",
      "Best performance on valid set upgraded: accuracy: 0.8251311870656645\n",
      "Best performance on valid set upgraded: accuracy: 0.8278258403063395\n",
      "[epoch]:1,[step]:50,[loss]:131.2823944091797,[score1]:0.969811320754717,[score2]:0.8251748251748252\n",
      "Best performance on valid set upgraded: accuracy: 0.8323642036590555\n",
      "Best performance on valid set upgraded: accuracy: 0.8357679761735924\n",
      "Best performance on valid set upgraded: accuracy: 0.8427173450574387\n",
      "Best performance on valid set upgraded: accuracy: 0.8517940717628705\n",
      "Best performance on valid set upgraded: accuracy: 0.8598780314848957\n",
      "Best performance on valid set upgraded: accuracy: 0.8658346333853354\n",
      "Best performance on valid set upgraded: accuracy: 0.8707984683023685\n",
      "Best performance on valid set upgraded: accuracy: 0.8770387179123529\n",
      "Best performance on valid set upgraded: accuracy: 0.8825698482484754\n",
      "Best performance on valid set upgraded: accuracy: 0.8844135583605163\n",
      "[epoch]:1,[step]:60,[loss]:94.23636627197266,[score1]:0.9859550561797753,[score2]:0.9407894736842105\n",
      "Best performance on valid set upgraded: accuracy: 0.8861154446177847\n",
      "Best performance on valid set upgraded: accuracy: 0.8881009785845979\n",
      "[epoch]:1,[step]:70,[loss]:59.95294952392578,[score1]:0.9798728813559322,[score2]:0.8977272727272727\n",
      "Best performance on valid set upgraded: accuracy: 0.8924975180825415\n",
      "Best performance on valid set upgraded: accuracy: 0.8951921713232166\n",
      "Best performance on valid set upgraded: accuracy: 0.8959012905970785\n",
      "Best performance on valid set upgraded: accuracy: 0.9021415402070628\n",
      "Best performance on valid set upgraded: accuracy: 0.9066799035597788\n",
      "Best performance on valid set upgraded: accuracy: 0.912494681605446\n",
      "[epoch]:1,[step]:80,[loss]:66.20378112792969,[score1]:0.984552008238929,[score2]:0.9365079365079365\n",
      "Best performance on valid set upgraded: accuracy: 0.9141965678627145\n",
      "[epoch]:1,[step]:90,[loss]:65.4464340209961,[score1]:0.977296181630547,[score2]:0.926829268292683\n",
      "Best performance on valid set upgraded: accuracy: 0.9188767550702028\n",
      "[epoch]:1,[step]:100,[loss]:71.0814208984375,[score1]:0.9791073124406457,[score2]:0.8484848484848485\n",
      "Best performance on valid set upgraded: accuracy: 0.9256843000992767\n",
      "Best performance on valid set upgraded: accuracy: 0.9296553680329032\n",
      "Best performance on valid set upgraded: accuracy: 0.9347610268047085\n",
      "Best performance on valid set upgraded: accuracy: 0.938732094738335\n",
      "Best performance on valid set upgraded: accuracy: 0.9390157424478798\n",
      "[epoch]:1,[step]:110,[loss]:65.9339370727539,[score1]:0.9858030168589175,[score2]:0.9064327485380117\n",
      "[epoch]:1,[step]:120,[loss]:89.24885559082031,[score1]:0.9780821917808219,[score2]:0.8920454545454546\n",
      "Best performance on valid set upgraded: accuracy: 0.9411431002694653\n",
      "Best performance on valid set upgraded: accuracy: 0.9428449865267338\n",
      "Best performance on valid set upgraded: accuracy: 0.9442632250744575\n",
      "Best performance on valid set upgraded: accuracy: 0.9449723443483193\n",
      "Best performance on valid set upgraded: accuracy: 0.9458232874769537\n",
      "[epoch]:1,[step]:130,[loss]:36.65972137451172,[score1]:0.9924457034938622,[score2]:0.9840425531914894\n",
      "Best performance on valid set upgraded: accuracy: 0.9458232874769537\n",
      "[epoch]:1,[step]:140,[loss]:64.14551544189453,[score1]:0.9841417910447762,[score2]:0.896969696969697\n",
      "Best performance on valid set upgraded: accuracy: 0.9483761168628563\n",
      "Best performance on valid set upgraded: accuracy: 0.9500780031201248\n",
      "Best performance on valid set upgraded: accuracy: 0.9500780031201248\n",
      "[epoch]:1,[step]:150,[loss]:41.05372619628906,[score1]:0.985981308411215,[score2]:0.9032258064516129\n",
      "Best performance on valid set upgraded: accuracy: 0.9513544178130762\n",
      "Best performance on valid set upgraded: accuracy: 0.9530563040703446\n",
      "Best performance on valid set upgraded: accuracy: 0.9536235994894341\n",
      "[epoch]:1,[step]:160,[loss]:71.50344848632812,[score1]:0.9782823297137216,[score2]:0.9030612244897959\n",
      "Best performance on valid set upgraded: accuracy: 0.9546163664728408\n",
      "Best performance on valid set upgraded: accuracy: 0.9558927811657921\n",
      "Best performance on valid set upgraded: accuracy: 0.9563182527301092\n",
      "[epoch]:1,[step]:170,[loss]:9.497894287109375,[score1]:0.9978021978021978,[score2]:1.0\n",
      "[epoch]:1,[step]:180,[loss]:27.025474548339844,[score1]:0.9952244508118434,[score2]:0.9695121951219512\n",
      "[epoch]:1,[step]:190,[loss]:50.54267120361328,[score1]:0.988795518207283,[score2]:0.95625\n",
      "[epoch]:1,[step]:200,[loss]:44.35765075683594,[score1]:0.9859550561797753,[score2]:0.9639175257731959\n",
      "Best performance on valid set upgraded: accuracy: 0.9564600765848815\n",
      "Best performance on valid set upgraded: accuracy: 0.957027372003971\n",
      "Best performance on valid set upgraded: accuracy: 0.957027372003971\n",
      "[epoch]:1,[step]:210,[loss]:88.6181411743164,[score1]:0.9816700610997964,[score2]:0.9337016574585635\n",
      "[epoch]:1,[step]:220,[loss]:43.82158660888672,[score1]:0.9846596356663471,[score2]:0.9779411764705882\n",
      "[epoch]:1,[step]:230,[loss]:29.96680450439453,[score1]:0.9855907780979827,[score2]:0.9597701149425287\n",
      "Best performance on valid set upgraded: accuracy: 0.9590129059707843\n",
      "[epoch]:1,[step]:240,[loss]:47.682411193847656,[score1]:0.9843587069864442,[score2]:0.9127906976744186\n",
      "Best performance on valid set upgraded: accuracy: 0.9600056729541909\n",
      "Best performance on valid set upgraded: accuracy: 0.9612820876471423\n",
      "Best performance on valid set upgraded: accuracy: 0.9625585023400937\n",
      "[epoch]:1,[step]:250,[loss]:39.98503112792969,[score1]:0.9873817034700315,[score2]:0.963963963963964\n",
      "[epoch]:1,[step]:260,[loss]:18.329116821289062,[score1]:0.9950248756218906,[score2]:0.9948453608247423\n",
      "Best performance on valid set upgraded: accuracy: 0.9625585023400937\n",
      "Best performance on valid set upgraded: accuracy: 0.963125797759183\n",
      "Best performance on valid set upgraded: accuracy: 0.9635512693235002\n",
      "[epoch]:1,[step]:270,[loss]:36.250083923339844,[score1]:0.9941690962099126,[score2]:0.9798657718120806\n",
      "[epoch]:1,[step]:280,[loss]:34.3468017578125,[score1]:0.9856459330143541,[score2]:0.9386503067484663\n",
      "[epoch]:1,[step]:290,[loss]:63.99800109863281,[score1]:0.9795918367346939,[score2]:0.9509803921568627\n",
      "[epoch]:1,[step]:300,[loss]:81.7618637084961,[score1]:0.972972972972973,[score2]:0.8693467336683417\n",
      "[epoch]:1,[step]:310,[loss]:31.628311157226562,[score1]:0.9874031007751938,[score2]:0.930379746835443\n",
      "Best performance on valid set upgraded: accuracy: 0.9636930931782726\n",
      "[epoch]:1,[step]:320,[loss]:34.66941833496094,[score1]:0.9867298578199052,[score2]:0.97\n",
      "[epoch]:1,[step]:330,[loss]:28.960372924804688,[score1]:0.9883495145631068,[score2]:0.9645390070921985\n",
      "[epoch]:1,[step]:340,[loss]:15.489837646484375,[score1]:0.9897003745318352,[score2]:0.9700598802395209\n",
      "Best performance on valid set upgraded: accuracy: 0.9638349170330449\n",
      "Best performance on valid set upgraded: accuracy: 0.9642603885973621\n",
      "Best performance on valid set upgraded: accuracy: 0.9656786271450858\n",
      "[epoch]:1,[step]:350,[loss]:26.087005615234375,[score1]:0.9937106918238994,[score2]:0.978021978021978\n",
      "Best performance on valid set upgraded: accuracy: 0.9675223372571267\n",
      "Best performance on valid set upgraded: accuracy: 0.9689405758048504\n",
      "Best performance on valid set upgraded: accuracy: 0.9699333427882569\n",
      "[epoch]:1,[step]:360,[loss]:25.99329376220703,[score1]:0.9933649289099526,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9716352290455255\n",
      "[epoch]:1,[step]:370,[loss]:21.516632080078125,[score1]:0.9930417495029821,[score2]:0.9698795180722891\n",
      "Best performance on valid set upgraded: accuracy: 0.9723443483193873\n",
      "Best performance on valid set upgraded: accuracy: 0.9731952914480215\n",
      "Best performance on valid set upgraded: accuracy: 0.9733371153027939\n",
      "Best performance on valid set upgraded: accuracy: 0.9747553538505177\n",
      "[epoch]:1,[step]:380,[loss]:40.71711730957031,[score1]:0.9833178869323448,[score2]:0.9266666666666666\n",
      "[epoch]:1,[step]:390,[loss]:15.025177001953125,[score1]:0.9921026653504442,[score2]:0.9753086419753086\n",
      "[epoch]:2,[step]:400,[loss]:12.73828125,[score1]:0.9948927477017364,[score2]:0.9606299212598425\n",
      "[epoch]:2,[step]:410,[loss]:33.137451171875,[score1]:0.991635687732342,[score2]:0.972972972972973\n",
      "[epoch]:2,[step]:420,[loss]:17.848373413085938,[score1]:0.9951690821256038,[score2]:0.9791666666666666\n",
      "Best performance on valid set upgraded: accuracy: 0.9753226492696071\n",
      "Best performance on valid set upgraded: accuracy: 0.9756062969791519\n",
      "[epoch]:2,[step]:430,[loss]:10.754310607910156,[score1]:0.99800796812749,[score2]:0.9927536231884058\n",
      "[epoch]:2,[step]:440,[loss]:29.574172973632812,[score1]:0.9898785425101214,[score2]:0.9634146341463414\n",
      "[epoch]:2,[step]:450,[loss]:3.2913970947265625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:460,[loss]:3.49200439453125,[score1]:0.9970355731225297,[score2]:0.9942196531791907\n",
      "[epoch]:2,[step]:470,[loss]:7.8379669189453125,[score1]:0.997196261682243,[score2]:0.9864864864864865\n",
      "[epoch]:2,[step]:480,[loss]:23.981460571289062,[score1]:0.9915333960489181,[score2]:0.9518072289156626\n",
      "[epoch]:2,[step]:490,[loss]:11.747100830078125,[score1]:0.99812382739212,[score2]:0.9901477832512315\n",
      "[epoch]:2,[step]:500,[loss]:28.758209228515625,[score1]:0.992091388400703,[score2]:0.9491525423728814\n",
      "[epoch]:2,[step]:510,[loss]:9.281242370605469,[score1]:0.9991319444444444,[score2]:1.0\n",
      "[epoch]:2,[step]:520,[loss]:15.810173034667969,[score1]:0.997131931166348,[score2]:0.9937106918238994\n",
      "[epoch]:2,[step]:530,[loss]:4.7498931884765625,[score1]:0.998019801980198,[score2]:0.9903381642512077\n",
      "[epoch]:2,[step]:540,[loss]:7.889404296875,[score1]:0.9913294797687862,[score2]:0.9708029197080292\n",
      "[epoch]:2,[step]:550,[loss]:27.382858276367188,[score1]:0.9933962264150943,[score2]:0.9608938547486033\n",
      "[epoch]:2,[step]:560,[loss]:39.977996826171875,[score1]:0.9923736892278361,[score2]:0.9742268041237113\n",
      "[epoch]:2,[step]:570,[loss]:6.477020263671875,[score1]:0.9951550387596899,[score2]:0.9698795180722891\n",
      "[epoch]:2,[step]:580,[loss]:2.4726715087890625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:590,[loss]:4.202545166015625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:600,[loss]:3.4504241943359375,[score1]:0.9989878542510121,[score2]:1.0\n",
      "[epoch]:2,[step]:610,[loss]:18.351303100585938,[score1]:0.9969072164948454,[score2]:0.9931506849315068\n",
      "[epoch]:2,[step]:620,[loss]:61.78759765625,[score1]:0.9824561403508771,[score2]:0.9341317365269461\n",
      "[epoch]:2,[step]:630,[loss]:21.769943237304688,[score1]:0.9948875255623721,[score2]:0.9702380952380952\n",
      "[epoch]:2,[step]:640,[loss]:28.627166748046875,[score1]:0.988256549232159,[score2]:0.9473684210526315\n",
      "[epoch]:2,[step]:650,[loss]:36.09877014160156,[score1]:0.9908906882591093,[score2]:0.9536423841059603\n",
      "[epoch]:2,[step]:660,[loss]:11.75238037109375,[score1]:0.99800796812749,[score2]:1.0\n",
      "[epoch]:2,[step]:670,[loss]:7.0525360107421875,[score1]:0.9970267591674926,[score2]:0.9885714285714285\n",
      "[epoch]:2,[step]:680,[loss]:19.63311767578125,[score1]:0.991,[score2]:0.9528795811518325\n",
      "[epoch]:2,[step]:690,[loss]:16.731613159179688,[score1]:0.9889112903225806,[score2]:0.9633507853403142\n",
      "[epoch]:2,[step]:700,[loss]:17.529998779296875,[score1]:0.9923809523809524,[score2]:0.9532163742690059\n",
      "[epoch]:2,[step]:710,[loss]:3.508575439453125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:2,[step]:720,[loss]:10.083023071289062,[score1]:0.9930830039525692,[score2]:0.9465648854961832\n",
      "[epoch]:2,[step]:730,[loss]:30.930572509765625,[score1]:0.99179580674567,[score2]:0.9574468085106383\n",
      "[epoch]:2,[step]:740,[loss]:34.024627685546875,[score1]:0.9920212765957447,[score2]:0.9625668449197861\n",
      "[epoch]:2,[step]:750,[loss]:4.2421417236328125,[score1]:0.9990842490842491,[score2]:0.9939024390243902\n",
      "[epoch]:2,[step]:760,[loss]:22.910308837890625,[score1]:0.9917948717948718,[score2]:0.971830985915493\n",
      "[epoch]:2,[step]:770,[loss]:12.0167236328125,[score1]:0.9935275080906149,[score2]:0.967032967032967\n",
      "[epoch]:2,[step]:780,[loss]:8.297866821289062,[score1]:0.999034749034749,[score2]:0.9935897435897436\n",
      "[epoch]:3,[step]:790,[loss]:4.48516845703125,[score1]:0.998165137614679,[score2]:0.9949494949494949\n",
      "[epoch]:3,[step]:800,[loss]:8.467681884765625,[score1]:0.99712368168744,[score2]:0.9834254143646409\n",
      "[epoch]:3,[step]:810,[loss]:14.672119140625,[score1]:0.996031746031746,[score2]:1.0\n",
      "[epoch]:3,[step]:820,[loss]:1.3479461669921875,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:830,[loss]:8.135757446289062,[score1]:0.9963768115942029,[score2]:0.9726027397260274\n",
      "[epoch]:3,[step]:840,[loss]:1.632720947265625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:850,[loss]:2.206695556640625,[score1]:0.9990467111534795,[score2]:1.0\n",
      "[epoch]:3,[step]:860,[loss]:6.2388916015625,[score1]:0.9991063449508489,[score2]:0.9951219512195122\n",
      "[epoch]:3,[step]:870,[loss]:3.3840789794921875,[score1]:0.99812734082397,[score2]:0.9833333333333333\n",
      "[epoch]:3,[step]:880,[loss]:8.081039428710938,[score1]:0.9939024390243902,[score2]:0.993006993006993\n",
      "[epoch]:3,[step]:890,[loss]:11.472732543945312,[score1]:0.9980676328502416,[score2]:0.9876543209876543\n",
      "[epoch]:3,[step]:900,[loss]:44.69050598144531,[score1]:0.9936421435059037,[score2]:0.9705882352941176\n",
      "[epoch]:3,[step]:910,[loss]:6.01434326171875,[score1]:0.9980694980694981,[score2]:0.9869281045751634\n",
      "[epoch]:3,[step]:920,[loss]:2.21343994140625,[score1]:0.9981981981981982,[score2]:1.0\n",
      "[epoch]:3,[step]:930,[loss]:5.9820709228515625,[score1]:0.9970703125,[score2]:0.9829545454545454\n",
      "[epoch]:3,[step]:940,[loss]:5.655181884765625,[score1]:0.9990842490842491,[score2]:0.995\n",
      "[epoch]:3,[step]:950,[loss]:13.311660766601562,[score1]:0.9990574929311969,[score2]:0.9924242424242424\n",
      "[epoch]:3,[step]:960,[loss]:3.2137603759765625,[score1]:0.9990783410138249,[score2]:0.9939024390243902\n",
      "[epoch]:3,[step]:970,[loss]:1.3861541748046875,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:980,[loss]:15.947219848632812,[score1]:0.9962546816479401,[score2]:0.9883720930232558\n",
      "[epoch]:3,[step]:990,[loss]:2.0123138427734375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1000,[loss]:10.175949096679688,[score1]:0.9929435483870968,[score2]:0.976878612716763\n",
      "Best performance on valid set upgraded: accuracy: 0.9757481208339243\n",
      "Best performance on valid set upgraded: accuracy: 0.9757481208339243\n",
      "[epoch]:3,[step]:1010,[loss]:12.244979858398438,[score1]:0.9960899315738025,[score2]:0.9754601226993865\n",
      "[epoch]:3,[step]:1020,[loss]:12.40301513671875,[score1]:0.9935125115848007,[score2]:0.9663461538461539\n",
      "[epoch]:3,[step]:1030,[loss]:9.794754028320312,[score1]:0.9970267591674926,[score2]:0.9876543209876543\n",
      "[epoch]:3,[step]:1040,[loss]:3.555450439453125,[score1]:0.9990281827016521,[score2]:0.9940119760479041\n",
      "[epoch]:3,[step]:1050,[loss]:7.768646240234375,[score1]:0.9972093023255814,[score2]:0.9883040935672515\n",
      "[epoch]:3,[step]:1060,[loss]:2.80157470703125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1070,[loss]:3.4276809692382812,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1080,[loss]:1.6380767822265625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1090,[loss]:1.0496673583984375,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1100,[loss]:3.323028564453125,[score1]:0.998991935483871,[score2]:0.9941860465116279\n",
      "[epoch]:3,[step]:1110,[loss]:2.2542877197265625,[score1]:0.9990029910269193,[score2]:0.9930555555555556\n",
      "[epoch]:3,[step]:1120,[loss]:0.6029205322265625,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1130,[loss]:10.148910522460938,[score1]:0.999031007751938,[score2]:0.9937888198757764\n",
      "Best performance on valid set upgraded: accuracy: 0.9763154162530138\n",
      "Best performance on valid set upgraded: accuracy: 0.9763154162530138\n",
      "[epoch]:3,[step]:1140,[loss]:14.60443115234375,[score1]:0.9964381121994658,[score2]:0.9883720930232558\n",
      "[epoch]:3,[step]:1150,[loss]:4.0013885498046875,[score1]:1.0,[score2]:1.0\n",
      "Best performance on valid set upgraded: accuracy: 0.9767408878173309\n",
      "Best performance on valid set upgraded: accuracy: 0.9768827116721033\n",
      "[epoch]:3,[step]:1160,[loss]:1.361846923828125,[score1]:1.0,[score2]:1.0\n",
      "[epoch]:3,[step]:1170,[loss]:1.5937957763671875,[score1]:0.9990601503759399,[score2]:1.0\n",
      "[epoch]:3,[step]:1180,[loss]:6.660736083984375,[score1]:0.9950835791543756,[score2]:0.9813664596273292\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from FreeLB import FreeLB\n",
    "model = NERModel()\n",
    "model.to(device)\n",
    "freelb = FreeLB(model=model)\n",
    "optimizer = AdamW(model.parameters(), lr=args['init_lr']) \n",
    "runner = NER_Runner_FreeLB(model,optimizer,freelb = freelb)\n",
    "runner.train(train_loader=loader,valid_loader=loader_valid,num_epoch=args['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1/score2 on test set:0.9923275058913794,0.9782947839652717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9923275058913794, 0.9782947839652717)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.predict(test_loader=loader_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kill iPython Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "pid = os.getpid()\n",
    "!kill -9 $pid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea09dad9c5cbe1dfe16e763c2b738244c66046026912720282114a9d0931e6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
